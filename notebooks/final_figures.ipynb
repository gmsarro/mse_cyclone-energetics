{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Figures — Cyclone Energetics Paper\n",
        "\n",
        "This notebook generates all final figures for the paper on cyclone energetics and\n",
        "the seasonal cycle of poleward energy transport.\n",
        "\n",
        "**Workflow summary:**\n",
        "1. Load integrated poleward flux data and cyclone area/intensity fields.\n",
        "2. Interpolate zonally averaged fields onto a fine latitude grid.\n",
        "3. Identify storm-track positions from the TE maximum/minimum.\n",
        "4. Decompose seasonal anomalies into footprint and efficiency terms.\n",
        "5. Generate bar charts for weak/strong and ocean/land comparisons.\n",
        "6. Produce 2-D maps and cyclone-centred composites."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pathlib\n",
        "import string\n",
        "\n",
        "import cartopy.crs\n",
        "import cartopy.feature\n",
        "import matplotlib as mpl\n",
        "import matplotlib.colors\n",
        "import matplotlib.patheffects\n",
        "import matplotlib.pyplot as plt\n",
        "import netCDF4\n",
        "import numpy as np\n",
        "import pandas\n",
        "import scipy.interpolate\n",
        "import xarray\n",
        "\n",
        "A_EARTH = 6.371e6\n",
        "AREA_CUT = \"0.225\"\n",
        "YEAR_START = 1979\n",
        "YEAR_END = 2015\n",
        "SEASON_LABELS = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
        "                 \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
        "\n",
        "BASE = pathlib.Path(\"/project2/tas1/gmsarro\")\n",
        "NC_FLUX = BASE / \"cyclone_centered\" / f\"WITH_INT_Cyclones_Sampled_Poleward_Fluxes_{AREA_CUT}.nc\"\n",
        "NC_ANT_INT = BASE / \"track\" / \"final\" / \"anticyclonic_intensity.nc\"\n",
        "NC_CYC_INT = BASE / \"track\" / \"final\" / \"cyclonic_intensity.nc\"\n",
        "CSV_DIR = BASE / \"track\" / \"final\"\n",
        "YEARLY_FILES = [\n",
        "    BASE / \"cyclone_centered\" / f\"WITH_INT_Cyclones_Sampled_Poleward_Fluxes_YEARS_{s}.nc\"\n",
        "    for s in range(3)\n",
        "]\n",
        "\n",
        "INTENSITY_CUT = np.array([1, 2, 3, 4, 5, 6])\n",
        "HALF_WIN = int(2844 / 2)\n",
        "PW_FACTOR = 2 * np.pi * A_EARTH / 1e15\n",
        "\n",
        "\n",
        "def _compute_confidence_numbers():\n",
        "    \"\"\"Compute interannual TE variability (CONF_NUM) from yearly data.\n",
        "\n",
        "    Returns (conf_c_a_SH, conf_c_a_NH, conf_6cvu_SH, conf_6cvu_NH).\n",
        "    \"\"\"\n",
        "    N_YEARS, N_MONTHS = 15, 12\n",
        "    x_d = np.linspace(0, 719, 719)\n",
        "    y_d = np.linspace(0, 12, 12)\n",
        "    x3_d = np.linspace(0, 719, 25600)\n",
        "\n",
        "    def _load_max_vals(intensity_cut, field_types):\n",
        "        max_vals = {}\n",
        "        stage, year_track = 0, 0\n",
        "        for yr in range(N_YEARS):\n",
        "            if yr == 5 or yr == 10:\n",
        "                stage += 1\n",
        "                year_track -= 5\n",
        "            with netCDF4.Dataset(str(YEARLY_FILES[stage]), \"r\") as ds:\n",
        "                latitude = np.asarray(ds[\"lat\"][:])\n",
        "                for ft in field_types:\n",
        "                    vn = f\"F_TE_final{ft}\" if ft else \"F_TE_final\"\n",
        "                    data_zon = np.mean(ds[vn][intensity_cut, :, year_track, :, :], axis=2)\n",
        "                    f_interp = scipy.interpolate.interp2d(x_d, y_d, data_zon, kind=\"cubic\")\n",
        "                    data_int = f_interp(x3_d, y_d)\n",
        "                    for hemi in (\"NH\", \"SH\"):\n",
        "                        if hemi == \"NH\":\n",
        "                            st = np.argmax(data_int, axis=1)\n",
        "                        else:\n",
        "                            st = np.argmin(data_int, axis=1)\n",
        "                        max_vals[(hemi, ft, yr)] = np.array([data_int[m, st[m]] for m in range(N_MONTHS)])\n",
        "            year_track += 1\n",
        "        return max_vals\n",
        "\n",
        "    def _smooth3(arr):\n",
        "        out = np.empty_like(arr)\n",
        "        out[1:-1] = (arr[:-2] + arr[1:-1] + arr[2:]) / 3.0\n",
        "        out[0] = (arr[-1] + arr[0] + arr[1]) / 3.0\n",
        "        out[-1] = (arr[-2] + arr[-1] + arr[0]) / 3.0\n",
        "        return out\n",
        "\n",
        "    # All cyclones: cycl + anti\n",
        "    mv_all = _load_max_vals(0, [\"_cycl\", \"_ant\", \"\"])\n",
        "    results = {}\n",
        "    for hemi in (\"SH\", \"NH\"):\n",
        "        conf = np.zeros(N_MONTHS)\n",
        "        for yr in range(N_YEARS - 1):\n",
        "            conf += np.abs(\n",
        "                (mv_all[(hemi, \"_cycl\", yr + 1)] + mv_all[(hemi, \"_ant\", yr + 1)])\n",
        "                - (mv_all[(hemi, \"_cycl\", yr)] + mv_all[(hemi, \"_ant\", yr)])\n",
        "            )\n",
        "        results[f\"c_a_{hemi}\"] = np.mean(conf / (N_YEARS - 1))\n",
        "\n",
        "    # 6+ CVU: cycl only, 3-pt smoothed\n",
        "    mv_6 = _load_max_vals(5, [\"_cycl\", \"\"])\n",
        "    for hemi in (\"SH\", \"NH\"):\n",
        "        conf = np.zeros(N_MONTHS)\n",
        "        for yr in range(N_YEARS - 1):\n",
        "            conf += np.abs(_smooth3(mv_6[(hemi, \"_cycl\", yr + 1)]) - _smooth3(mv_6[(hemi, \"_cycl\", yr)]))\n",
        "        results[f\"6cvu_{hemi}\"] = np.mean(conf / (N_YEARS - 1))\n",
        "\n",
        "    return results[\"c_a_SH\"], results[\"c_a_NH\"], results[\"6cvu_SH\"], results[\"6cvu_NH\"]\n",
        "\n",
        "\n",
        "CONF_NUM_C_A_SH, CONF_NUM_C_A_NH, CONF_NUM_6CVU_SH, CONF_NUM_6CVU_NH = _compute_confidence_numbers()\n",
        "print(f\"CONF_NUM_C_A_SH  = {CONF_NUM_C_A_SH:.16f}\")\n",
        "print(f\"CONF_NUM_C_A_NH  = {CONF_NUM_C_A_NH:.16f}\")\n",
        "print(f\"CONF_NUM_6CVU_SH = {CONF_NUM_6CVU_SH:.16f}\")\n",
        "print(f\"CONF_NUM_6CVU_NH = {CONF_NUM_6CVU_NH:.16f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def running_mean(*, data, window_size):\n",
        "    kernel = np.ones(window_size) / window_size\n",
        "    return np.convolve(data, kernel, mode=\"same\")\n",
        "\n",
        "\n",
        "def interp_lat_2d(*, field_12x_nlat, x_d, y_d, x3_d, y3_d):\n",
        "    f = scipy.interpolate.interp2d(x_d, y_d, field_12x_nlat, kind=\"cubic\")\n",
        "    return f(x3_d, y3_d)\n",
        "\n",
        "\n",
        "def fine_lat(*, latitude, x_d, x3_d):\n",
        "    f = scipy.interpolate.interp1d(x_d, latitude)\n",
        "    return f(x3_d)\n",
        "\n",
        "\n",
        "def stormtrack_from_total_fte(*, fte_zon_int, lat_fine):\n",
        "    st_nh = np.argmax(fte_zon_int, axis=1)\n",
        "    st_sh = np.argmin(fte_zon_int, axis=1)\n",
        "    return st_nh, st_sh, lat_fine[st_nh], lat_fine[st_sh]\n",
        "\n",
        "\n",
        "def mean_around_track(*, field_12x_nfine, idx_12, half_win=HALF_WIN):\n",
        "    out = np.zeros(12)\n",
        "    for n in range(12):\n",
        "        i0 = idx_12[n] - half_win\n",
        "        i1 = idx_12[n] + half_win\n",
        "        out[n] = np.mean(field_12x_nfine[n, i0:i1])\n",
        "    return out\n",
        "\n",
        "\n",
        "def seasonal_diff(x):\n",
        "    x = np.asarray(x)\n",
        "    return np.mean(x[[11, 0, 1]]) - np.mean(x[[5, 6, 7]])\n",
        "\n",
        "\n",
        "def load_nc_var(*, path, variable_name):\n",
        "    with netCDF4.Dataset(str(path), \"r\") as ds:\n",
        "        return ds.variables[variable_name][:]\n",
        "\n",
        "\n",
        "def allocate_bands_from_variability(*, term2, term3, band_total):\n",
        "    s2 = np.nanstd(term2)\n",
        "    s3 = np.nanstd(term3)\n",
        "    if not np.isfinite(s2 + s3) or (s2 + s3) == 0:\n",
        "        w2 = 0.5\n",
        "    else:\n",
        "        w2 = s2 / (s2 + s3)\n",
        "    w3 = 1.0 - w2\n",
        "    return w2 * band_total, w3 * band_total, w2, w3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load integrated flux data and compute storm-track positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with netCDF4.Dataset(str(NC_FLUX)) as ds:\n",
        "    latitude = ds[\"lat\"][:]\n",
        "    longitude = ds[\"lon\"][:]\n",
        "\n",
        "    F_TE_final_total = ds[\"F_TE_final\"][0, :, :, :]\n",
        "    F_TE_final_cycl_all = ds[\"F_TE_final_cycl\"][0, :, :, :]\n",
        "    F_TE_final_cycl_strong = ds[\"F_TE_final_cycl\"][5, :, :, :]\n",
        "    F_TE_final_ant_all = ds[\"F_TE_final_ant\"][0, :, :, :]\n",
        "\n",
        "    tot_energy_final_cycl_0 = ds[\"tot_energy_final_cycl\"][0, :, :, :]\n",
        "    tot_energy_final_cycl_5 = ds[\"tot_energy_final_cycl\"][5, :, :, :]\n",
        "    F_Swabs_final_cycl_0 = ds[\"F_Swabs_final_cycl\"][0, :, :, :]\n",
        "    F_Swabs_final_cycl_5 = ds[\"F_Swabs_final_cycl\"][5, :, :, :]\n",
        "    F_Olr_final_cycl_0 = ds[\"F_Olr_final_cycl\"][0, :, :, :]\n",
        "    F_Olr_final_cycl_5 = ds[\"F_Olr_final_cycl\"][5, :, :, :]\n",
        "    F_Dhdt_final_cycl_0 = ds[\"F_Dhdt_final_cycl\"][0, :, :, :]\n",
        "    F_Dhdt_final_cycl_5 = ds[\"F_Dhdt_final_cycl\"][5, :, :, :]\n",
        "    F_TE_final_cycl_0 = ds[\"F_TE_final_cycl\"][0, :, :, :]\n",
        "    F_TE_final_cycl_5 = ds[\"F_TE_final_cycl\"][5, :, :, :]\n",
        "    F_TE_z_final_cycl_0 = ds[\"F_TE_z_final_cycl\"][0, :, :, :]\n",
        "    F_TE_z_final_cycl_5 = ds[\"F_TE_z_final_cycl\"][5, :, :, :]\n",
        "    F_u_mse_final_cycl_5 = ds[\"F_u_mse_final_cycl\"][5, :, :, :]\n",
        "\n",
        "ant_int_final = load_nc_var(path=NC_ANT_INT, variable_name=\"ant_int_final\")\n",
        "cycl_int_final = load_nc_var(path=NC_CYC_INT, variable_name=\"cycl_int_final\")\n",
        "\n",
        "nlat = len(latitude)\n",
        "x_d = np.linspace(0, nlat - 1, nlat)\n",
        "y_d = np.linspace(0, 12, 12)\n",
        "x3_d = np.linspace(0, nlat - 1, 25600)\n",
        "y3_d = np.linspace(0, 12, 12)\n",
        "Lat = fine_lat(latitude=latitude, x_d=x_d, x3_d=x3_d)\n",
        "\n",
        "F_TE_final_zon_int = interp_lat_2d(\n",
        "    field_12x_nlat=np.mean(F_TE_final_total, axis=2),\n",
        "    x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d,\n",
        ")\n",
        "stormtrack_NH, stormtrack_SH, stormtrack_lat_nh, stormtrack_lat_sh = stormtrack_from_total_fte(\n",
        "    fte_zon_int=F_TE_final_zon_int, lat_fine=Lat,\n",
        ")\n",
        "max_TE_position = Lat[np.argmax(F_TE_final_zon_int, axis=1)]\n",
        "max_TE_SH_position = Lat[np.argmin(F_TE_final_zon_int, axis=1)]\n",
        "\n",
        "print(\"Storm-track NH latitudes:\", stormtrack_lat_nh)\n",
        "print(\"Storm-track SH latitudes:\", stormtrack_lat_sh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load track density CSVs and compute intensity/count seasonality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lat_grid = np.linspace(-90, 90, 181)\n",
        "cosine_weights = np.cos(np.radians(lat_grid))\n",
        "lat_res = 181\n",
        "\n",
        "latitudinally_count_all = np.zeros((12, lat_res), float)\n",
        "latitudinally_count_6cvu = np.zeros((12, lat_res), float)\n",
        "\n",
        "for k, month_name in enumerate(SEASON_LABELS):\n",
        "    grit_count = pandas.read_csv(str(CSV_DIR / f\"{month_name}_count.csv\")).values\n",
        "    step = np.nanmean(grit_count, axis=1) * cosine_weights\n",
        "    latitudinally_count_all[k, :] = step * 3 / (YEAR_END - YEAR_START)\n",
        "\n",
        "    grit_count_6 = pandas.read_csv(str(CSV_DIR / f\"{month_name}_count_6CVU.csv\")).values\n",
        "    step_6 = np.nanmean(grit_count_6, axis=1) * cosine_weights\n",
        "    latitudinally_count_6cvu[k, :] = step_6 * 3 / (YEAR_END - YEAR_START)\n",
        "\n",
        "local_count_NH_all = np.zeros(12)\n",
        "local_count_SH_all = np.zeros(12)\n",
        "local_count_NH_6cvu = np.zeros(12)\n",
        "local_count_SH_6cvu = np.zeros(12)\n",
        "\n",
        "for n in range(12):\n",
        "    for k in range(lat_res // 2, lat_res):\n",
        "        if lat_grid[k] == int(Lat[stormtrack_NH[n]]):\n",
        "            local_count_NH_all[n] = np.mean(\n",
        "                latitudinally_count_all[n, k - 10 : k + 11]\n",
        "                - latitudinally_count_6cvu[n, k - 10 : k + 11]\n",
        "            )\n",
        "            local_count_NH_6cvu[n] = np.mean(\n",
        "                latitudinally_count_6cvu[n, k - 10 : k + 11]\n",
        "            )\n",
        "\n",
        "for n in range(12):\n",
        "    for k in range(0, lat_res // 2):\n",
        "        if lat_grid[k] == int(Lat[stormtrack_SH[n]]):\n",
        "            local_count_SH_all[n - 6] = np.mean(\n",
        "                latitudinally_count_all[n, k - 10 : k + 11]\n",
        "                - latitudinally_count_6cvu[n, k - 10 : k + 11]\n",
        "            )\n",
        "            local_count_SH_6cvu[n - 6] = np.mean(\n",
        "                latitudinally_count_6cvu[n, k - 10 : k + 11]\n",
        "            )\n",
        "\n",
        "plot_1_nh = local_count_NH_all - np.mean(local_count_NH_all)\n",
        "plot_1_sh = local_count_SH_all - np.mean(local_count_SH_all)\n",
        "plot_1_nh_6cvu = local_count_NH_6cvu - np.mean(local_count_NH_6cvu)\n",
        "plot_1_sh_6cvu = local_count_SH_6cvu - np.mean(local_count_SH_6cvu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute area and TE seasonality decomposition (1–5 CVU and 6+ CVU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_area_means(*, st_nh, st_sh):\n",
        "    area_mean = {\"ant\": {\"NH\": {}, \"SH\": {}}, \"cycl\": {\"NH\": {}, \"SH\": {}}}\n",
        "    for cut_idx in range(6):\n",
        "        ant_zon = np.mean(ant_int_final[cut_idx, :, :, :], axis=2)\n",
        "        cyc_zon = np.mean(cycl_int_final[cut_idx, :, :, :], axis=2)\n",
        "        ant_intp = interp_lat_2d(field_12x_nlat=ant_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "        cyc_intp = interp_lat_2d(field_12x_nlat=cyc_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "        bin_num = cut_idx + 1\n",
        "        area_mean[\"ant\"][\"NH\"][bin_num] = np.mean(mean_around_track(field_12x_nfine=ant_intp, idx_12=st_nh))\n",
        "        area_mean[\"ant\"][\"SH\"][bin_num] = np.mean(mean_around_track(field_12x_nfine=ant_intp, idx_12=st_sh))\n",
        "        area_mean[\"cycl\"][\"NH\"][bin_num] = np.mean(mean_around_track(field_12x_nfine=cyc_intp, idx_12=st_nh))\n",
        "        area_mean[\"cycl\"][\"SH\"][bin_num] = np.mean(mean_around_track(field_12x_nfine=cyc_intp, idx_12=st_sh))\n",
        "    return area_mean\n",
        "\n",
        "\n",
        "area_cycl_all_zon_int = {}\n",
        "for cut_idx in range(6):\n",
        "    for prefix, data in [(\"ant\", ant_int_final), (\"cycl\", cycl_int_final)]:\n",
        "        zon = np.mean(data[cut_idx, :, :, :], axis=2)\n",
        "        intp = interp_lat_2d(field_12x_nlat=zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "        nh_vals = mean_around_track(field_12x_nfine=intp, idx_12=stormtrack_NH)\n",
        "        sh_vals = np.zeros(12)\n",
        "        for n in range(12):\n",
        "            sh_vals[n - 6] = np.mean(\n",
        "                intp[n, stormtrack_SH[n] - HALF_WIN : stormtrack_SH[n] + HALF_WIN]\n",
        "            )\n",
        "        area_cycl_all_zon_int[f\"{AREA_CUT}max_NH_{cut_idx + 1}_final_{prefix}_zon_int\"] = nh_vals\n",
        "        area_cycl_all_zon_int[f\"{AREA_CUT}max_SH_{cut_idx + 1}_final_{prefix}_zon_int\"] = sh_vals\n",
        "        di_nh = nh_vals - np.mean(nh_vals)\n",
        "        di_sh = sh_vals - np.mean(sh_vals)\n",
        "        area_cycl_all_zon_int[f\"{AREA_CUT}D_I_NH_{cut_idx + 1}_final_{prefix}_zon_int\"] = di_nh\n",
        "        area_cycl_all_zon_int[f\"{AREA_CUT}D_I_SH_{cut_idx + 1}_final_{prefix}_zon_int\"] = di_sh\n",
        "\n",
        "area_mean_bins = compute_area_means(st_nh=stormtrack_NH, st_sh=stormtrack_SH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_flux_zonal_exact(*, intensity_idx):\n",
        "    with netCDF4.Dataset(str(NC_FLUX), \"r\") as ds:\n",
        "        lat = ds[\"lat\"][:]\n",
        "        F_TE_total = ds[\"F_TE_final\"][intensity_idx, :, :, :]\n",
        "        if intensity_idx == 0:\n",
        "            base = 5\n",
        "            sw_cycl = ds[\"F_Swabs_final_cycl\"][0, :, :, :] - ds[\"F_Swabs_final_cycl\"][base, :, :, :]\n",
        "            olr_cycl = ds[\"F_Olr_final_cycl\"][0, :, :, :] - ds[\"F_Olr_final_cycl\"][base, :, :, :]\n",
        "            dhdt_cycl = ds[\"F_Dhdt_final_cycl\"][0, :, :, :] - ds[\"F_Dhdt_final_cycl\"][base, :, :, :]\n",
        "            te_cycl = ds[\"F_TE_final_cycl\"][0, :, :, :] - ds[\"F_TE_final_cycl\"][base, :, :, :]\n",
        "            tot_cycl = (\n",
        "                ds[\"tot_energy_final_cycl\"][0, :, :, :]\n",
        "                - ds[\"tot_energy_final_cycl\"][base, :, :, :]\n",
        "            ) + dhdt_cycl\n",
        "            umz_cycl = ds[\"F_TE_z_final_cycl\"][0, :, :, :] - ds[\"F_TE_z_final_cycl\"][base, :, :, :]\n",
        "        else:\n",
        "            sw_cycl = ds[\"F_Swabs_final_cycl\"][intensity_idx, :, :, :]\n",
        "            olr_cycl = ds[\"F_Olr_final_cycl\"][intensity_idx, :, :, :]\n",
        "            dhdt_cycl = ds[\"F_Dhdt_final_cycl\"][intensity_idx, :, :, :]\n",
        "            te_cycl = ds[\"F_TE_final_cycl\"][intensity_idx, :, :, :]\n",
        "            tot_cycl = (\n",
        "                ds[\"tot_energy_final_cycl\"][intensity_idx, :, :, :]\n",
        "                + ds[\"F_Dhdt_final_cycl\"][intensity_idx, :, :, :]\n",
        "            )\n",
        "            umz_cycl = ds[\"F_u_mse_final_cycl\"][intensity_idx, :, :, :]\n",
        "    out = {\n",
        "        \"latitude\": lat,\n",
        "        \"F_TE_total_zon\": np.mean(F_TE_total, axis=2),\n",
        "        \"tot_energy_cycl_zon\": np.mean(tot_cycl, axis=2),\n",
        "        \"F_Swabs_cycl_zon\": np.mean(sw_cycl, axis=2),\n",
        "        \"F_Olr_cycl_zon\": np.mean(olr_cycl, axis=2),\n",
        "        \"F_Dhdt_cycl_zon\": np.mean(dhdt_cycl, axis=2),\n",
        "        \"F_TE_cycl_zon\": np.mean(te_cycl, axis=2),\n",
        "        \"F_UM_z_cycl_zon\": np.mean(umz_cycl, axis=2),\n",
        "    }\n",
        "    out[\"F_Shf_cycl_zon\"] = out[\"tot_energy_cycl_zon\"] - out[\"F_Olr_cycl_zon\"] - out[\"F_Swabs_cycl_zon\"]\n",
        "    return out\n",
        "\n",
        "\n",
        "def compute_DI_for_intensity(*, intensity_idx, area_mean_bins):\n",
        "    Z = load_flux_zonal_exact(intensity_idx=intensity_idx)\n",
        "    lat_f = fine_lat(latitude=Z[\"latitude\"], x_d=x_d, x3_d=x3_d)\n",
        "    fte_int = interp_lat_2d(\n",
        "        field_12x_nlat=Z[\"F_TE_total_zon\"], x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d,\n",
        "    )\n",
        "    st_nh, st_sh, stlat_nh, stlat_sh = stormtrack_from_total_fte(\n",
        "        fte_zon_int=fte_int, lat_fine=lat_f,\n",
        "    )\n",
        "    bin_num = intensity_idx + 1\n",
        "    area_nh = area_mean_bins[\"cycl\"][\"NH\"][bin_num]\n",
        "    area_sh = area_mean_bins[\"cycl\"][\"SH\"][bin_num]\n",
        "\n",
        "    def norm_factor(*, lat_deg, area_mean):\n",
        "        return A_EARTH * np.cos(np.deg2rad(lat_deg)) * 2 * np.pi * area_mean\n",
        "\n",
        "    out = {}\n",
        "    for flux_key, field_name in [\n",
        "        (\"tot_energy\", \"tot_energy_cycl_zon\"),\n",
        "        (\"F_TE\", \"F_TE_cycl_zon\"),\n",
        "        (\"F_Swabs\", \"F_Swabs_cycl_zon\"),\n",
        "        (\"F_Olr\", \"F_Olr_cycl_zon\"),\n",
        "        (\"F_Shf\", \"F_Shf_cycl_zon\"),\n",
        "        (\"F_Dhdt\", \"F_Dhdt_cycl_zon\"),\n",
        "        (\"F_UM_z\", \"F_UM_z_cycl_zon\"),\n",
        "    ]:\n",
        "        fld_int = interp_lat_2d(\n",
        "            field_12x_nlat=Z[field_name], x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d,\n",
        "        )\n",
        "        nh_raw = mean_around_track(field_12x_nfine=fld_int, idx_12=st_nh) / norm_factor(\n",
        "            lat_deg=stlat_nh, area_mean=area_nh,\n",
        "        )\n",
        "        sh_raw = mean_around_track(field_12x_nfine=fld_int, idx_12=st_sh) / norm_factor(\n",
        "            lat_deg=stlat_sh, area_mean=area_sh,\n",
        "        )\n",
        "        out[f\"D_I_NH_{flux_key}{intensity_idx}\"] = nh_raw - np.mean(nh_raw)\n",
        "        out[f\"D_I_SH_{flux_key}{intensity_idx}\"] = sh_raw - np.mean(sh_raw)\n",
        "    out[\"stormtrack_lat_nh\"] = stlat_nh\n",
        "    out[\"stormtrack_lat_sh\"] = stlat_sh\n",
        "    return out\n",
        "\n",
        "\n",
        "DI_weak = compute_DI_for_intensity(intensity_idx=0, area_mean_bins=area_mean_bins)\n",
        "DI_strong = compute_DI_for_intensity(intensity_idx=5, area_mean_bins=area_mean_bins)\n",
        "\n",
        "confidence_c_a_SH = CONF_NUM_C_A_SH / 4 / (\n",
        "    A_EARTH * np.cos(np.deg2rad(np.mean(stormtrack_lat_sh))) * 2 * np.pi\n",
        "    * (area_mean_bins[\"cycl\"][\"SH\"][1] + area_mean_bins[\"ant\"][\"SH\"][1])\n",
        ")\n",
        "confidence_c_a_NH = CONF_NUM_C_A_NH / 4 / (\n",
        "    A_EARTH * np.cos(np.deg2rad(np.mean(stormtrack_lat_nh))) * 2 * np.pi\n",
        "    * (area_mean_bins[\"cycl\"][\"NH\"][1] + area_mean_bins[\"ant\"][\"NH\"][1])\n",
        ")\n",
        "confidence_6cvu_SH = CONF_NUM_6CVU_SH / 2 / (\n",
        "    A_EARTH * np.cos(np.deg2rad(np.mean(stormtrack_lat_nh))) * 2 * np.pi\n",
        "    * area_mean_bins[\"cycl\"][\"NH\"][5]\n",
        ")\n",
        "confidence_6cvu_NH = CONF_NUM_6CVU_NH / 2 / (\n",
        "    A_EARTH * np.cos(np.deg2rad(np.mean(stormtrack_lat_sh))) * 2 * np.pi\n",
        "    * area_mean_bins[\"cycl\"][\"SH\"][5]\n",
        ")\n",
        "\n",
        "confidence_6cvu_SH_track = 0.6610716237042479 / 2.5\n",
        "confidence_6cvu_NH_track = 0.36348897259838214 / 2.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute TE seasonality decomposition terms (footprint vs efficiency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _compute_3term_decomposition(*, intensity_idx, area_cut_str, di_dict):\n",
        "    with netCDF4.Dataset(str(NC_FLUX)) as ds:\n",
        "        lat = ds[\"lat\"][:]\n",
        "        F_TE_total = ds[\"F_TE_final\"][intensity_idx, :, :, :]\n",
        "        if intensity_idx == 0:\n",
        "            F_TE_cycl = ds[\"F_TE_final_cycl\"][0, :, :, :] - ds[\"F_TE_final_cycl\"][5, :, :, :]\n",
        "        else:\n",
        "            F_TE_cycl = ds[\"F_TE_final_cycl\"][intensity_idx, :, :, :]\n",
        "\n",
        "    F_TE_total_zon = np.mean(F_TE_total, axis=2)\n",
        "    F_TE_cycl_zon = np.mean(F_TE_cycl, axis=2)\n",
        "    F_TE_total_int = interp_lat_2d(field_12x_nlat=F_TE_total_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "    F_TE_cycl_int = interp_lat_2d(field_12x_nlat=F_TE_cycl_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "\n",
        "    lat_f = fine_lat(latitude=lat, x_d=x_d, x3_d=x3_d)\n",
        "    st_nh_t, st_sh_t, _, _ = stormtrack_from_total_fte(fte_zon_int=F_TE_total_int, lat_fine=lat_f)\n",
        "\n",
        "    cut = 0 if intensity_idx == 0 else 5\n",
        "    area_key_nh = f\"{area_cut_str}max_NH_{INTENSITY_CUT[cut]}_final_cycl_zon_int\"\n",
        "    area_key_sh = f\"{area_cut_str}max_SH_{INTENSITY_CUT[cut]}_final_cycl_zon_int\"\n",
        "    area_nh = area_cycl_all_zon_int[area_key_nh]\n",
        "    area_sh = area_cycl_all_zon_int[area_key_sh]\n",
        "\n",
        "    first_term_NH = np.zeros(12)\n",
        "    first_term_SH = np.zeros(12)\n",
        "    for n in range(12):\n",
        "        flux_nh = np.mean(F_TE_cycl_int[n, st_nh_t[n] - HALF_WIN : st_nh_t[n] + HALF_WIN])\n",
        "        flux_sh = np.mean(F_TE_cycl_int[n, st_sh_t[n] - HALF_WIN : st_sh_t[n] + HALF_WIN])\n",
        "        first_term_NH[n] = flux_nh / (\n",
        "            np.cos(np.deg2rad(lat_f[st_nh_t[n]])) * area_nh[n]\n",
        "        )\n",
        "        first_term_SH[n] = flux_sh / (\n",
        "            np.cos(np.deg2rad(lat_f[st_sh_t[n]])) * area_sh[n - 6]\n",
        "        )\n",
        "\n",
        "    plot_2_nh = np.zeros(12)\n",
        "    plot_2_sh = np.zeros(12)\n",
        "    plot_4_nh = np.zeros(12)\n",
        "    plot_4_sh = np.zeros(12)\n",
        "    plot_5_nh = np.zeros(12)\n",
        "    plot_5_sh = np.zeros(12)\n",
        "\n",
        "    for n in range(12):\n",
        "        flux_nh = np.mean(F_TE_cycl_int[n, st_nh_t[n] - HALF_WIN : st_nh_t[n] + HALF_WIN])\n",
        "        flux_sh = np.mean(F_TE_cycl_int[n, st_sh_t[n] - HALF_WIN : st_sh_t[n] + HALF_WIN])\n",
        "\n",
        "        plot_2_nh[n] = flux_nh / (\n",
        "            np.cos(np.deg2rad(lat_f[st_nh_t[n]])) * np.mean(area_nh)\n",
        "        )\n",
        "        plot_2_sh[n] = flux_sh / (\n",
        "            np.cos(np.deg2rad(lat_f[st_sh_t[n]])) * np.mean(area_sh)\n",
        "        )\n",
        "        plot_4_nh[n] = flux_nh / (\n",
        "            np.cos(np.deg2rad(lat_f[st_nh_t[n]])) * area_nh[n]\n",
        "        )\n",
        "        plot_4_sh[n] = flux_sh / (\n",
        "            np.cos(np.deg2rad(lat_f[st_sh_t[n]])) * area_sh[n - 6]\n",
        "        )\n",
        "        plot_5_nh[n] = np.mean(first_term_NH) * (\n",
        "            np.cos(np.deg2rad(lat_f[st_nh_t[n]])) * area_nh[n]\n",
        "        ) / np.mean(area_nh)\n",
        "        plot_5_sh[n] = np.mean(first_term_SH) * (\n",
        "            np.cos(np.deg2rad(lat_f[st_sh_t[n]])) * area_sh[n - 6]\n",
        "        ) / np.mean(area_sh)\n",
        "\n",
        "    return {\n",
        "        \"plot_2_nh\": plot_2_nh - np.mean(plot_2_nh),\n",
        "        \"plot_2_sh\": plot_2_sh - np.mean(plot_2_sh),\n",
        "        \"plot_4_nh\": plot_4_nh - np.mean(plot_4_nh),\n",
        "        \"plot_4_sh\": plot_4_sh - np.mean(plot_4_sh),\n",
        "        \"plot_5_nh\": plot_5_nh - np.mean(plot_5_nh),\n",
        "        \"plot_5_sh\": plot_5_sh - np.mean(plot_5_sh),\n",
        "        \"first_term_NH\": first_term_NH,\n",
        "        \"first_term_SH\": first_term_SH,\n",
        "    }\n",
        "\n",
        "\n",
        "decomp_15 = _compute_3term_decomposition(\n",
        "    intensity_idx=0, area_cut_str=AREA_CUT, di_dict=DI_weak,\n",
        ")\n",
        "decomp_6 = _compute_3term_decomposition(\n",
        "    intensity_idx=5, area_cut_str=AREA_CUT, di_dict=DI_strong,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figure 1 — Seasonality 3-panel (total transport, footprint, efficiency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mpl.rcParams.update({\n",
        "    \"font.size\": 18,\n",
        "    \"axes.spines.top\": False,\n",
        "    \"axes.spines.right\": False,\n",
        "    \"axes.linewidth\": 1.2,\n",
        "    \"xtick.major.size\": 5,\n",
        "    \"ytick.major.size\": 5,\n",
        "})\n",
        "\n",
        "RED_LIGHT = \"#f8766d\"\n",
        "RED_DARK = \"#b22222\"\n",
        "BLUE_LIGHT = \"#00bfc4\"\n",
        "BLUE_DARK = \"#1f4e79\"\n",
        "GRAY_BAND = \"0.85\"\n",
        "\n",
        "SMOOTH_WINDOW = 3\n",
        "x_ax = np.arange(12)\n",
        "xlabels = SEASON_LABELS\n",
        "\n",
        "t1_nh_15 = running_mean(data=decomp_15[\"plot_2_nh\"], window_size=SMOOTH_WINDOW)\n",
        "t1_sh_15 = running_mean(data=decomp_15[\"plot_2_sh\"], window_size=SMOOTH_WINDOW)\n",
        "t1_nh_6 = running_mean(data=decomp_6[\"plot_2_nh\"], window_size=SMOOTH_WINDOW)\n",
        "t1_sh_6 = running_mean(data=decomp_6[\"plot_2_sh\"], window_size=SMOOTH_WINDOW)\n",
        "\n",
        "t2_nh_15 = running_mean(data=decomp_15[\"plot_5_nh\"], window_size=SMOOTH_WINDOW)\n",
        "t2_sh_15 = running_mean(data=decomp_15[\"plot_5_sh\"], window_size=SMOOTH_WINDOW)\n",
        "t2_nh_6 = running_mean(data=decomp_6[\"plot_5_nh\"], window_size=SMOOTH_WINDOW)\n",
        "t2_sh_6 = running_mean(data=decomp_6[\"plot_5_sh\"], window_size=SMOOTH_WINDOW)\n",
        "\n",
        "t3_nh_15 = running_mean(data=decomp_15[\"plot_4_nh\"], window_size=SMOOTH_WINDOW)\n",
        "t3_sh_15 = running_mean(data=decomp_15[\"plot_4_sh\"], window_size=SMOOTH_WINDOW)\n",
        "t3_nh_6 = running_mean(data=decomp_6[\"plot_4_nh\"], window_size=SMOOTH_WINDOW)\n",
        "t3_sh_6 = running_mean(data=decomp_6[\"plot_4_sh\"], window_size=SMOOTH_WINDOW)\n",
        "\n",
        "band_t1 = float(np.nanmax([np.abs(confidence_6cvu_NH), np.abs(confidence_6cvu_SH)]))\n",
        "band_t2, band_t3, w2, w3 = allocate_bands_from_variability(\n",
        "    term2=t2_sh_6, term3=t3_sh_6, band_total=band_t1,\n",
        ")\n",
        "\n",
        "all_series = np.array([\n",
        "    t1_nh_15, t1_sh_15, t1_nh_6, t1_sh_6,\n",
        "    t2_nh_15, t2_sh_15, t2_nh_6, t2_sh_6,\n",
        "    t3_nh_15, t3_sh_15, t3_nh_6, t3_sh_6,\n",
        "], dtype=float)\n",
        "ymax = 1.05 * np.nanmax([np.nanmax(np.abs(all_series)), band_t1, band_t2, band_t3])\n",
        "ylims = (-ymax, ymax)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(19.5, 6.8), sharey=True, constrained_layout=False)\n",
        "fig.subplots_adjust(left=0.085, right=0.985, top=0.90, bottom=0.20, wspace=0.28)\n",
        "\n",
        "MS_15, LW_15, LW_6, ALPHA_15 = 7, 3, 5, 0.9\n",
        "\n",
        "for j, ax in enumerate(axs):\n",
        "    ax.set_xlim(x_ax[0], x_ax[-1])\n",
        "    ax.grid(True, linewidth=0.6, alpha=0.25)\n",
        "    ax.set_xticks(x_ax[::2])\n",
        "    ax.set_xticklabels([xlabels[i] for i in range(0, 12, 2)], fontsize=14)\n",
        "    ax.set_ylim(*ylims)\n",
        "    if j > 0:\n",
        "        ax.tick_params(labelleft=False)\n",
        "\n",
        "ax0 = axs[0]\n",
        "ax0.axhspan(-band_t1, band_t1, color=GRAY_BAND, alpha=0.6, zorder=0)\n",
        "l1, = ax0.plot(x_ax, t1_nh_15, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=RED_LIGHT, label=\"1\\u20135 CVU NH\")\n",
        "l2, = ax0.plot(x_ax, t1_sh_15, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=BLUE_LIGHT, label=\"1\\u20135 CVU SH\")\n",
        "l3, = ax0.plot(x_ax, t1_nh_6, marker=\".\", lw=LW_6, color=RED_DARK, label=\"6+ CVU NH\")\n",
        "l4, = ax0.plot(x_ax, t1_sh_6, marker=\".\", lw=LW_6, color=BLUE_DARK, label=\"6+ CVU SH\")\n",
        "ax0.axhline(0, color=\"black\", ls=\"--\", lw=1)\n",
        "ax0.set_title(\"(a) Total transport seasonality\", fontsize=20, pad=16)\n",
        "ax0.set_xlabel(\"Month\", fontsize=18)\n",
        "ax0.set_ylabel(\"PW\", fontsize=18)\n",
        "ax0.legend([l1, l2, l3, l4], [h.get_label() for h in [l1, l2, l3, l4]],\n",
        "           fontsize=14, frameon=True, framealpha=0.85, loc=\"upper center\",\n",
        "           bbox_to_anchor=(0.5, 1), ncol=2)\n",
        "\n",
        "ax1 = axs[1]\n",
        "ax1.axhspan(-band_t2, band_t2, color=GRAY_BAND, alpha=0.6, zorder=0)\n",
        "ax1.plot(x_ax, t2_nh_15, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=RED_LIGHT)\n",
        "ax1.plot(x_ax, t2_sh_15, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=BLUE_LIGHT)\n",
        "ax1.plot(x_ax, t2_nh_6, marker=\".\", lw=LW_6, color=RED_DARK)\n",
        "ax1.plot(x_ax, t2_sh_6, marker=\".\", lw=LW_6, color=BLUE_DARK)\n",
        "ax1.axhline(0, color=\"black\", ls=\"--\", lw=1)\n",
        "ax1.set_title(\"(b) Change in footprint\", fontsize=20, pad=16)\n",
        "ax1.set_xlabel(\"Month\", fontsize=18)\n",
        "\n",
        "ax2 = axs[2]\n",
        "ax2.axhspan(-band_t3, band_t3, color=GRAY_BAND, alpha=0.6, zorder=0)\n",
        "ax2.plot(x_ax, t3_nh_15, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=RED_LIGHT)\n",
        "ax2.plot(x_ax, t3_sh_15, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=BLUE_LIGHT)\n",
        "ax2.plot(x_ax, t3_nh_6, marker=\".\", lw=LW_6, color=RED_DARK)\n",
        "ax2.plot(x_ax, t3_sh_6, marker=\".\", lw=LW_6, color=BLUE_DARK)\n",
        "ax2.axhline(0, color=\"black\", ls=\"--\", lw=1)\n",
        "ax2.set_title(\"(c) Change in cyclone efficiency\", fontsize=20, pad=16)\n",
        "ax2.set_xlabel(\"Month\", fontsize=18)\n",
        "\n",
        "pos0 = ax0.get_position()\n",
        "pos1 = ax1.get_position()\n",
        "pos2 = ax2.get_position()\n",
        "x_sep = 0.5 * (pos0.x1 + pos1.x0)\n",
        "y0_fig = min(pos0.y0, pos1.y0, pos2.y0)\n",
        "y1_fig = max(pos0.y1, pos1.y1, pos2.y1)\n",
        "fig.add_artist(mpl.lines.Line2D([x_sep, x_sep], [y0_fig, y1_fig],\n",
        "               transform=fig.transFigure, color=\"black\", lw=1.2, alpha=0.7))\n",
        "fig.text(x_sep, 0.5 * (y0_fig + y1_fig), \"=\", ha=\"center\", va=\"center\", fontsize=26)\n",
        "x_plus = 0.5 * (pos1.x1 + pos2.x0)\n",
        "fig.text(x_plus, 0.5 * (y0_fig + y1_fig), \"+\", ha=\"center\", va=\"center\", fontsize=26)\n",
        "\n",
        "plt.savefig(\"Seasonality_3panel_PW.png\", dpi=600, facecolor=\"white\", bbox_inches=\"tight\")\n",
        "plt.savefig(\"Seasonality_3panel_PW.pdf\", dpi=600, facecolor=\"white\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figure 2 — Area percent and track density seasonality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "area_nh_15 = area_cycl_all_zon_int[f\"{AREA_CUT}max_NH_1_final_cycl_zon_int\"]\n",
        "area_sh_15 = area_cycl_all_zon_int[f\"{AREA_CUT}max_SH_1_final_cycl_zon_int\"]\n",
        "area_nh_6 = area_cycl_all_zon_int[f\"{AREA_CUT}max_NH_6_final_cycl_zon_int\"]\n",
        "area_sh_6 = area_cycl_all_zon_int[f\"{AREA_CUT}max_SH_6_final_cycl_zon_int\"]\n",
        "\n",
        "AREA_TO_PERCENT = 100.0\n",
        "area_nh_15_anom = AREA_TO_PERCENT * area_nh_15 - np.nanmean(AREA_TO_PERCENT * area_nh_15)\n",
        "area_sh_15_anom = AREA_TO_PERCENT * area_sh_15 - np.nanmean(AREA_TO_PERCENT * area_sh_15)\n",
        "area_nh_6_anom = AREA_TO_PERCENT * area_nh_6 - np.nanmean(AREA_TO_PERCENT * area_nh_6)\n",
        "area_sh_6_anom = AREA_TO_PERCENT * area_sh_6 - np.nanmean(AREA_TO_PERCENT * area_sh_6)\n",
        "\n",
        "band_track = float(np.nanmax([np.abs(confidence_6cvu_SH_track), np.abs(confidence_6cvu_NH_track)]))\n",
        "\n",
        "td_nh_15 = running_mean(data=plot_1_nh, window_size=3)\n",
        "td_sh_15 = running_mean(data=plot_1_sh, window_size=3)\n",
        "td_nh_6 = running_mean(data=plot_1_nh_6cvu, window_size=3)\n",
        "td_sh_6 = running_mean(data=plot_1_sh_6cvu, window_size=3)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(13.8, 6.8), constrained_layout=False)\n",
        "fig.subplots_adjust(left=0.08, right=0.985, top=0.90, bottom=0.20, wspace=0.22)\n",
        "\n",
        "for ax in axs:\n",
        "    ax.set_xlim(x_ax[0], x_ax[-1])\n",
        "    ax.grid(True, linewidth=0.6, alpha=0.25)\n",
        "    ax.set_xticks(x_ax[::2])\n",
        "    ax.set_xticklabels([xlabels[i] for i in range(0, 12, 2)], fontsize=14)\n",
        "\n",
        "ax0 = axs[0]\n",
        "band_area = 1.027\n",
        "ax0.axhspan(-band_area, band_area, color=GRAY_BAND, alpha=0.6, zorder=0)\n",
        "l1, = ax0.plot(x_ax, area_nh_15_anom, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=RED_LIGHT, label=\"1\\u20135 CVU NH\")\n",
        "l2, = ax0.plot(x_ax, area_sh_15_anom, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=BLUE_LIGHT, label=\"1\\u20135 CVU SH\")\n",
        "l3, = ax0.plot(x_ax, area_nh_6_anom, marker=\".\", lw=LW_6, color=RED_DARK, label=\"6+ CVU NH\")\n",
        "l4, = ax0.plot(x_ax, area_sh_6_anom, marker=\".\", lw=LW_6, color=BLUE_DARK, label=\"6+ CVU SH\")\n",
        "ax0.axhline(0, color=\"black\", ls=\"--\", lw=1)\n",
        "ax0.set_title(\"(a) Assigned Area seasonality\", fontsize=20, pad=16)\n",
        "ax0.set_xlabel(\"Month\", fontsize=18)\n",
        "ax0.set_ylabel(\"% of latitude circle\", fontsize=18)\n",
        "ax0.legend([l1, l2, l3, l4], [h.get_label() for h in [l1, l2, l3, l4]],\n",
        "           fontsize=14, frameon=True, framealpha=0.85, loc=\"upper center\",\n",
        "           bbox_to_anchor=(0.5, 1), ncol=2)\n",
        "\n",
        "ax1 = axs[1]\n",
        "ax1.axhspan(-band_track, band_track, color=GRAY_BAND, alpha=0.6, zorder=0)\n",
        "ax1.plot(x_ax, td_nh_15, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=RED_LIGHT)\n",
        "ax1.plot(x_ax, td_sh_15, \"-\", marker=\".\", ms=MS_15, lw=LW_15, alpha=ALPHA_15, color=BLUE_LIGHT)\n",
        "ax1.plot(x_ax, td_nh_6, marker=\".\", lw=LW_6, color=RED_DARK)\n",
        "ax1.plot(x_ax, td_sh_6, marker=\".\", lw=LW_6, color=BLUE_DARK)\n",
        "ax1.axhline(0, color=\"black\", ls=\"--\", lw=1)\n",
        "ax1.set_title(\"(b) Track density seasonality\", fontsize=20, pad=16)\n",
        "ax1.set_xlabel(\"Month\", fontsize=18)\n",
        "ax1.set_ylabel(r\"# / month / 5$^\\circ$\", fontsize=18)\n",
        "\n",
        "plt.savefig(\"AreaPercent_and_TrackDensity_Seasonality.png\", dpi=600, facecolor=\"white\", bbox_inches=\"tight\")\n",
        "plt.savefig(\"AreaPercent_and_TrackDensity_Seasonality.pdf\", dpi=600, facecolor=\"white\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figure 3 — Time and zonal mean transient-eddy transport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "F_TE_cycl_weak = F_TE_final_cycl_all - F_TE_final_cycl_strong\n",
        "F_TE_cycl_plus_ant = F_TE_final_cycl_all + F_TE_final_ant_all\n",
        "\n",
        "def zonal_time_mean(field):\n",
        "    return field.mean(axis=(0, 2))\n",
        "\n",
        "TE_total_lat = zonal_time_mean(F_TE_final_total)\n",
        "TE_ant_lat = zonal_time_mean(F_TE_final_ant_all)\n",
        "TE_cycl_weak_lat = zonal_time_mean(F_TE_cycl_weak)\n",
        "TE_cycl_strong_lat = zonal_time_mean(F_TE_final_cycl_strong)\n",
        "TE_cycl_plus_ant_lat = zonal_time_mean(F_TE_cycl_plus_ant)\n",
        "\n",
        "window = 15\n",
        "TE_total_smooth = running_mean(data=TE_total_lat, window_size=window)\n",
        "TE_ant_smooth = running_mean(data=TE_ant_lat, window_size=window)\n",
        "TE_cycl_weak_smooth = running_mean(data=TE_cycl_weak_lat, window_size=window)\n",
        "TE_cycl_strong_smooth = running_mean(data=TE_cycl_strong_lat, window_size=window)\n",
        "TE_cycl_plus_ant_smooth = running_mean(data=TE_cycl_plus_ant_lat, window_size=window)\n",
        "\n",
        "if not np.all(np.diff(latitude) > 0):\n",
        "    sort_idx = np.argsort(latitude)\n",
        "    lat_sorted = latitude[sort_idx]\n",
        "    TE_total_smooth = TE_total_smooth[sort_idx]\n",
        "    TE_ant_smooth = TE_ant_smooth[sort_idx]\n",
        "    TE_cycl_weak_smooth = TE_cycl_weak_smooth[sort_idx]\n",
        "    TE_cycl_strong_smooth = TE_cycl_strong_smooth[sort_idx]\n",
        "    TE_cycl_plus_ant_smooth = TE_cycl_plus_ant_smooth[sort_idx]\n",
        "else:\n",
        "    lat_sorted = latitude\n",
        "\n",
        "nh_mask = (lat_sorted >= 10) & (lat_sorted <= 80)\n",
        "if nh_mask.any():\n",
        "    nh_idx = np.argmax(TE_total_smooth[nh_mask])\n",
        "    storm_idx = np.where(nh_mask)[0][nh_idx]\n",
        "    storm_lat = lat_sorted[storm_idx]\n",
        "    storm_val = TE_total_smooth[storm_idx]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 4.5))\n",
        "ax.axhline(0, color=\"0.6\", linestyle=\"--\", linewidth=1)\n",
        "ax.plot(lat_sorted, TE_total_smooth, color=\"red\", linewidth=2.0, label=\"Mask=1 everywhere\")\n",
        "ax.plot(lat_sorted, TE_ant_smooth, color=\"blue\", linewidth=2.0, label=\"Anticyclones\")\n",
        "ax.plot(lat_sorted, TE_cycl_weak_smooth, color=\"green\", linewidth=2.0, label=\"Cyclones 1\\u20135 CVU\")\n",
        "ax.plot(lat_sorted, TE_cycl_strong_smooth, color=\"purple\", linewidth=2.0, label=\"Cyclones \\u2265 6 CVU\")\n",
        "ax.plot(lat_sorted, TE_cycl_plus_ant_smooth, linestyle=\"--\", linewidth=2.0, color=\"black\",\n",
        "        label=\"Cyclones + anticyclones\")\n",
        "if nh_mask.any():\n",
        "    ax.plot(storm_lat, storm_val, marker=\"*\", markersize=10, color=\"k\", zorder=5)\n",
        "ax.set_xlim(-90, 90)\n",
        "ymax = np.max(np.abs([TE_total_smooth, TE_ant_smooth, TE_cycl_weak_smooth,\n",
        "                       TE_cycl_strong_smooth, TE_cycl_plus_ant_smooth]))\n",
        "ax.set_ylim(-1.05 * ymax, 1.05 * ymax)\n",
        "ax.set_xlabel(\"Latitude (deg)\")\n",
        "ax.set_ylabel(\"Transient Eddy PW\")\n",
        "ax.set_title(\"Time and zonal mean TE\")\n",
        "ax.legend(loc=\"upper left\", frameon=False)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figure 4 — Weak vs strong cyclones bar chart (PW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flux_labels_base = [\"Transient Eddy\", \"Radiation\", \"SHF\", \"dh/dt\", \"Zonal Advection\", \"Residual\"]\n",
        "bar_colors = [\"firebrick\", \"darkviolet\", \"blue\", \"black\", \"darkgreen\", \"gray\"]\n",
        "\n",
        "panels = [\n",
        "    (\"SH\", 0, confidence_c_a_SH, \"SH 1-5 CVU\"),\n",
        "    (\"NH\", 0, confidence_c_a_NH, \"NH 1-5 CVU\"),\n",
        "    (\"SH\", 5, confidence_6cvu_SH, \"SH 6+ CVU\"),\n",
        "    (\"NH\", 5, confidence_6cvu_NH, \"NH 6+ CVU\"),\n",
        "]\n",
        "\n",
        "data_dict = {}\n",
        "for key, val in DI_weak.items():\n",
        "    if not key.startswith(\"stormtrack\"):\n",
        "        data_dict[key] = val\n",
        "for key, val in DI_strong.items():\n",
        "    if not key.startswith(\"stormtrack\"):\n",
        "        data_dict[key] = val\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(18, 10), sharey=True)\n",
        "\n",
        "for i, (ax, (hemi, icut, conf, title)) in enumerate(zip(axs.flat, panels)):\n",
        "    values = []\n",
        "    te = data_dict[f\"D_I_{hemi}_F_TE{icut}\"] * 1e15 * PW_FACTOR\n",
        "    values.append(np.mean(te[[11, 0, 1]]) - np.mean(te[[5, 6, 7]]))\n",
        "\n",
        "    swabs = data_dict[f\"D_I_{hemi}_F_Swabs{icut}\"] * 1e15 * PW_FACTOR\n",
        "    olr = data_dict[f\"D_I_{hemi}_F_Olr{icut}\"] * 1e15 * PW_FACTOR\n",
        "    values.append(np.mean((swabs + olr)[[11, 0, 1]]) - np.mean((swabs + olr)[[5, 6, 7]]))\n",
        "\n",
        "    shf = data_dict[f\"D_I_{hemi}_F_Shf{icut}\"] * 1e15 * PW_FACTOR\n",
        "    values.append(np.mean(shf[[11, 0, 1]]) - np.mean(shf[[5, 6, 7]]))\n",
        "\n",
        "    dhdt = -data_dict[f\"D_I_{hemi}_F_Dhdt{icut}\"] * 1e15 * PW_FACTOR\n",
        "    values.append(np.mean(dhdt[[11, 0, 1]]) - np.mean(dhdt[[5, 6, 7]]))\n",
        "\n",
        "    umz = -data_dict[f\"D_I_{hemi}_F_UM_z{icut}\"] * 1e15 * PW_FACTOR\n",
        "    values.append(np.mean(umz[[11, 0, 1]]) - np.mean(umz[[5, 6, 7]]))\n",
        "\n",
        "    tot = data_dict[f\"D_I_{hemi}_tot_energy{icut}\"] * 1e15 * PW_FACTOR\n",
        "    te_raw = data_dict[f\"D_I_{hemi}_F_TE{icut}\"]\n",
        "    dhdt_raw = data_dict[f\"D_I_{hemi}_F_Dhdt{icut}\"]\n",
        "    tot_raw = data_dict[f\"D_I_{hemi}_tot_energy{icut}\"]\n",
        "    umz_raw = data_dict[f\"D_I_{hemi}_F_UM_z{icut}\"]\n",
        "    residual = (te_raw - (tot_raw - dhdt_raw) + umz_raw) * 1e15 * PW_FACTOR\n",
        "    values.append(np.mean(residual[[11, 0, 1]]) - np.mean(residual[[5, 6, 7]]))\n",
        "\n",
        "    x_bar = np.arange(len(values))\n",
        "    ax.bar(x_bar, values, color=bar_colors, edgecolor=\"black\")\n",
        "    ax.axvline(0.5, color=\"black\", linestyle=\"--\", linewidth=1.5)\n",
        "    ax.fill_between([-0.5, len(x_bar) - 0.5],\n",
        "                    conf * 1e15 * PW_FACTOR, -conf * 1e15 * PW_FACTOR,\n",
        "                    color=\"gray\", alpha=0.7)\n",
        "    ax.axhline(0, color=\"black\", linestyle=\"-\", linewidth=1.2)\n",
        "\n",
        "    if hemi == \"SH\":\n",
        "        flux_labels = [f\"-{lab}\" for lab in flux_labels_base]\n",
        "    else:\n",
        "        flux_labels = flux_labels_base\n",
        "    ax.set_xticks(x_bar)\n",
        "    ax.set_xticklabels(flux_labels, rotation=25, fontsize=18, ha=\"right\")\n",
        "    letter = string.ascii_lowercase[i]\n",
        "    ax.set_title(f\"({letter}) {title}\", fontsize=18)\n",
        "    ax.set_ylabel(\"Winter \\u2013 Summer (PW)\", fontsize=18)\n",
        "    ax.tick_params(axis=\"y\", labelsize=18)\n",
        "\n",
        "fig.suptitle(\"Seasonal Difference in Integrated Flux Terms (Winter \\u2013 Summer)\", fontsize=22)\n",
        "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "fig.savefig(\"weak_vs_strong_PW_winter_minus_summer_textonly.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figure 5 — Ocean vs land (NH, C+A and 6+ CVU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with netCDF4.Dataset(str(NC_FLUX), \"r\") as ds:\n",
        "    F_VM_final_ant0 = ds[\"F_VM_final_ant\"][0, 0, :, :]\n",
        "\n",
        "    sw_ca0 = ds[\"F_Swabs_final_cycl\"][0, :, :, :] + ds[\"F_Swabs_final_ant\"][0, :, :, :]\n",
        "    olr_ca0 = ds[\"F_Olr_final_cycl\"][0, :, :, :] + ds[\"F_Olr_final_ant\"][0, :, :, :]\n",
        "    dhdt_ca0 = ds[\"F_Dhdt_final_cycl\"][0, :, :, :] + ds[\"F_Dhdt_final_ant\"][0, :, :, :]\n",
        "    te_ca0 = ds[\"F_TE_final_cycl\"][0, :, :, :] + ds[\"F_TE_final_ant\"][0, :, :, :]\n",
        "    umz_ca0 = ds[\"F_u_mse_final_cycl\"][0, :, :, :] + ds[\"F_u_mse_final_ant\"][0, :, :, :]\n",
        "    tot_ca0 = (\n",
        "        ds[\"tot_energy_final_cycl\"][0, :, :, :]\n",
        "        + ds[\"tot_energy_final_ant\"][0, :, :, :]\n",
        "    ) + dhdt_ca0\n",
        "    shf_ca0 = tot_ca0 - olr_ca0 - sw_ca0\n",
        "\n",
        "    tot_c5 = ds[\"tot_energy_final_cycl\"][5, :, :, :] + ds[\"F_Dhdt_final_cycl\"][5, :, :, :]\n",
        "    sw_c5 = ds[\"F_Swabs_final_cycl\"][5, :, :, :]\n",
        "    olr_c5 = ds[\"F_Olr_final_cycl\"][5, :, :, :]\n",
        "    dhdt_c5 = ds[\"F_Dhdt_final_cycl\"][5, :, :, :]\n",
        "    te_c5 = ds[\"F_TE_final_cycl\"][5, :, :, :]\n",
        "    umz_c5 = ds[\"F_u_mse_final_cycl\"][5, :, :, :]\n",
        "    shf_c5 = tot_c5 - olr_c5 - sw_c5\n",
        "\n",
        "map_mask = np.copy(F_VM_final_ant0) * 0 + 1\n",
        "map_mask[361:, :] = 0\n",
        "map_mask[:, 0:450] = 0\n",
        "map_mask[:230, 950:1140] = 0\n",
        "map_mask[:190, 900:950] = 0\n",
        "map_mask[:190, 1140:1200] = 0\n",
        "map_mask[:220, 450:550] = 0\n",
        "map_mask[:270, 450:490] = 0\n",
        "map_mask[:130, 450:1350] = 0\n",
        "map_mask[180:350, 1390:] = 0\n",
        "map_mask[320:, 1120:1240] = 0\n",
        "map_mask[:40, :] = 1\n",
        "map_mask[280:361, 220:380] = 1\n",
        "map_mask[:90, :60] = 1\n",
        "map_mask[200:270, 490:550] = 1\n",
        "map_mask[180:210, 0:90] = 1\n",
        "map_mask[230:, :] = 0\n",
        "\n",
        "land_mask = (map_mask - 1) * (-1)\n",
        "land_mask[361:, :] = 0\n",
        "land_mask[230:, :] = 0\n",
        "\n",
        "ocean_mask_expanded = np.expand_dims(map_mask, axis=0)\n",
        "land_mask_expanded = np.expand_dims(land_mask, axis=0)\n",
        "\n",
        "cycl_area_cut1_zon = np.mean(cycl_int_final[0, :, :, :], axis=2)\n",
        "ant_area_cut1_zon = np.mean(ant_int_final[0, :, :, :], axis=2)\n",
        "cycl_area_cut6_zon = np.mean(cycl_int_final[5, :, :, :], axis=2)\n",
        "\n",
        "cycl_area_cut1_int = interp_lat_2d(field_12x_nlat=cycl_area_cut1_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "ant_area_cut1_int = interp_lat_2d(field_12x_nlat=ant_area_cut1_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "cycl_area_cut6_int = interp_lat_2d(field_12x_nlat=cycl_area_cut6_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "\n",
        "max_area_NH_cycl_cut1 = mean_around_track(field_12x_nfine=cycl_area_cut1_int, idx_12=stormtrack_NH)\n",
        "max_area_NH_ant_cut1 = mean_around_track(field_12x_nfine=ant_area_cut1_int, idx_12=stormtrack_NH)\n",
        "max_area_NH_CA_cut1 = max_area_NH_cycl_cut1 + max_area_NH_ant_cut1\n",
        "max_area_NH_cut6 = mean_around_track(field_12x_nfine=cycl_area_cut6_int, idx_12=stormtrack_NH)\n",
        "\n",
        "cycl6_land_zon = np.mean(cycl_int_final[5, :, :, :] * land_mask_expanded, axis=2)\n",
        "cycl6_oce_zon = np.mean(cycl_int_final[5, :, :, :] * ocean_mask_expanded, axis=2)\n",
        "cycl6_land_int = interp_lat_2d(field_12x_nlat=cycl6_land_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "cycl6_oce_int = interp_lat_2d(field_12x_nlat=cycl6_oce_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "max_area_NH_cut6_land = mean_around_track(field_12x_nfine=cycl6_land_int, idx_12=stormtrack_NH)\n",
        "max_area_NH_cut6_oce = mean_around_track(field_12x_nfine=cycl6_oce_int, idx_12=stormtrack_NH)\n",
        "\n",
        "land_mask_avg = np.mean(land_mask_expanded, axis=2)\n",
        "ocean_mask_avg = np.mean(ocean_mask_expanded, axis=2)\n",
        "land_mask_rep = np.repeat(land_mask_avg, 12, axis=0)\n",
        "ocean_mask_rep = np.repeat(ocean_mask_avg, 12, axis=0)\n",
        "land_mask_int = scipy.interpolate.interp2d(x_d, y_d, land_mask_rep, kind=\"cubic\")(x3_d, y3_d)\n",
        "ocean_mask_int = scipy.interpolate.interp2d(x_d, y_d, ocean_mask_rep, kind=\"cubic\")(x3_d, y3_d)\n",
        "ocean_frac_at_track = np.array([ocean_mask_int[0, i] for i in stormtrack_NH])\n",
        "land_frac_at_track = np.array([land_mask_int[0, i] for i in stormtrack_NH])\n",
        "area_oce_CA_cut1 = max_area_NH_CA_cut1 * ocean_frac_at_track\n",
        "area_lan_CA_cut1 = max_area_NH_CA_cut1 * land_frac_at_track"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_DI_NH_from_fields(*, fields, denom_mode, denom_values):\n",
        "    out = {}\n",
        "    denom_mean = float(np.mean(denom_values))\n",
        "    for flux_name, arr in fields.items():\n",
        "        arr_zon = np.mean(arr, axis=2)\n",
        "        arr_int = interp_lat_2d(field_12x_nlat=arr_zon, x_d=x_d, y_d=y_d, x3_d=x3_d, y3_d=y3_d)\n",
        "        maxN = mean_around_track(field_12x_nfine=arr_int, idx_12=stormtrack_NH)\n",
        "        if denom_mode == \"per_month\":\n",
        "            norm = A_EARTH * np.cos(np.deg2rad(stormtrack_lat_nh)) * 2 * np.pi * denom_values\n",
        "        else:\n",
        "            norm = A_EARTH * np.cos(np.deg2rad(stormtrack_lat_nh)) * 2 * np.pi * denom_mean\n",
        "        series = maxN / norm\n",
        "        out[flux_name] = series - np.mean(series)\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_bar_values_pw(*, DI):\n",
        "    te = DI[\"F_TE\"] * 1e15\n",
        "    swabs = DI[\"F_Swabs\"] * 1e15\n",
        "    olr = DI[\"F_Olr\"] * 1e15\n",
        "    shf = DI[\"F_Shf\"] * 1e15\n",
        "    dhdt = -DI[\"F_Dhdt\"] * 1e15\n",
        "    umz = -DI[\"F_UM_z\"] * 1e15\n",
        "    tot = DI[\"tot_energy\"] * 1e15\n",
        "    residual = te - (tot - (-dhdt)) + (-umz)\n",
        "    values = [\n",
        "        seasonal_diff(te), seasonal_diff(swabs + olr), seasonal_diff(shf),\n",
        "        seasonal_diff(dhdt), seasonal_diff(umz), seasonal_diff(residual),\n",
        "    ]\n",
        "    return [v * PW_FACTOR for v in values]\n",
        "\n",
        "\n",
        "def _make_field_dict(*, te, sw, olr, shf, dhdt, umz, tot, mask):\n",
        "    return {\n",
        "        \"F_TE\": te * mask, \"F_Swabs\": sw * mask, \"F_Olr\": olr * mask,\n",
        "        \"F_Shf\": shf * mask, \"F_Dhdt\": dhdt * mask, \"F_UM_z\": umz * mask,\n",
        "        \"tot_energy\": tot * mask,\n",
        "    }\n",
        "\n",
        "\n",
        "D_I_ca_oce = compute_DI_NH_from_fields(\n",
        "    fields=_make_field_dict(te=te_ca0, sw=sw_ca0, olr=olr_ca0, shf=shf_ca0,\n",
        "                           dhdt=dhdt_ca0, umz=umz_ca0, tot=tot_ca0, mask=ocean_mask_expanded),\n",
        "    denom_mode=\"per_month\", denom_values=area_oce_CA_cut1,\n",
        ")\n",
        "D_I_ca_lan = compute_DI_NH_from_fields(\n",
        "    fields=_make_field_dict(te=te_ca0, sw=sw_ca0, olr=olr_ca0, shf=shf_ca0,\n",
        "                           dhdt=dhdt_ca0, umz=umz_ca0, tot=tot_ca0, mask=land_mask_expanded),\n",
        "    denom_mode=\"per_month\", denom_values=area_lan_CA_cut1,\n",
        ")\n",
        "\n",
        "ones_mask = np.ones_like(ocean_mask_expanded)\n",
        "D_I_cycl5_total = compute_DI_NH_from_fields(\n",
        "    fields=_make_field_dict(te=te_c5, sw=sw_c5, olr=olr_c5, shf=shf_c5,\n",
        "                           dhdt=dhdt_c5, umz=umz_c5, tot=tot_c5, mask=ones_mask),\n",
        "    denom_mode=\"mean\", denom_values=max_area_NH_cut6,\n",
        ")\n",
        "D_I_cycl5_land = compute_DI_NH_from_fields(\n",
        "    fields=_make_field_dict(te=te_c5, sw=sw_c5, olr=olr_c5, shf=shf_c5,\n",
        "                           dhdt=dhdt_c5, umz=umz_c5, tot=tot_c5, mask=land_mask_expanded),\n",
        "    denom_mode=\"mean\", denom_values=max_area_NH_cut6_land,\n",
        ")\n",
        "D_I_cycl5_oce = compute_DI_NH_from_fields(\n",
        "    fields=_make_field_dict(te=te_c5, sw=sw_c5, olr=olr_c5, shf=shf_c5,\n",
        "                           dhdt=dhdt_c5, umz=umz_c5, tot=tot_c5, mask=ocean_mask_expanded),\n",
        "    denom_mode=\"mean\", denom_values=max_area_NH_cut6_oce,\n",
        ")\n",
        "\n",
        "confidence_eulerian_NH = 0.3694333379314638 / 2 / (\n",
        "    A_EARTH * np.cos(np.deg2rad(np.mean(stormtrack_lat_nh))) * 2 * np.pi\n",
        ")\n",
        "\n",
        "results_land_ocean = {\n",
        "    \"C + A Land\": build_bar_values_pw(DI=D_I_ca_lan),\n",
        "    \"C + A Ocean\": build_bar_values_pw(DI=D_I_ca_oce),\n",
        "    \"C 6+ CVU Land\": build_bar_values_pw(DI=D_I_cycl5_land),\n",
        "    \"C 6+ CVU Ocean\": build_bar_values_pw(DI=D_I_cycl5_oce),\n",
        "}\n",
        "conf_dict_pw = {\n",
        "    \"C + A Land\": confidence_eulerian_NH * 1e15 * PW_FACTOR,\n",
        "    \"C + A Ocean\": confidence_eulerian_NH * 1e15 * PW_FACTOR,\n",
        "    \"C 6+ CVU Land\": confidence_6cvu_NH * 1e15 * PW_FACTOR,\n",
        "    \"C 6+ CVU Ocean\": confidence_6cvu_NH * 1e15 * PW_FACTOR,\n",
        "}\n",
        "\n",
        "bar_labels = [\"Transient Eddy\", \"Radiation\", \"SHF\", \"dh/dt\", \"Zonal Advection\", \"Residual\"]\n",
        "x_bar = np.arange(len(bar_labels))\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(18, 12), sharey=True)\n",
        "categories = [\"C + A Land\", \"C + A Ocean\", \"C 6+ CVU Land\", \"C 6+ CVU Ocean\"]\n",
        "\n",
        "for i, region in enumerate(categories):\n",
        "    ax = axs[i // 2, i % 2]\n",
        "    ax.bar(x_bar, results_land_ocean[region], color=bar_colors, edgecolor=\"black\")\n",
        "    ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
        "    ax.axvline(0.5, color=\"black\", linestyle=\"--\", linewidth=1.5)\n",
        "    ax.set_xticks(x_bar)\n",
        "    ax.set_xticklabels(bar_labels, rotation=25, ha=\"right\", fontsize=18)\n",
        "    letter = string.ascii_lowercase[i]\n",
        "    ax.set_title(f\"({letter}) {region}\", fontsize=18)\n",
        "    if i % 2 == 0:\n",
        "        ax.set_ylabel(\"Winter \\u2013 Summer (PW)\", fontsize=18)\n",
        "    ax.fill_between([-0.5, len(x_bar) - 0.5],\n",
        "                    conf_dict_pw[region], -conf_dict_pw[region],\n",
        "                    color=\"gray\", alpha=0.7)\n",
        "    ax.tick_params(axis=\"y\", labelsize=18)\n",
        "\n",
        "fig.suptitle(\"NH Seasonal Difference in Integrated Flux Terms (Winter \\u2013 Summer, PW)\", fontsize=22)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "fig.savefig(\"CA_land_ocean_plus_6CVU_land_ocean_pw_FIXED.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figure 6 — 2-D global maps (weak and strong cyclone TE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.transforms as _mt\n",
        "_orig_union = _mt.Bbox.union\n",
        "def _safe_union(bboxes):\n",
        "    if not len(bboxes):\n",
        "        return _mt.Bbox.unit()\n",
        "    return _orig_union(bboxes)\n",
        "_mt.Bbox.union = staticmethod(_safe_union)\n",
        "\n",
        "mpl.rcParams.update({\n",
        "    \"font.size\": 16,\n",
        "    \"axes.spines.top\": False,\n",
        "    \"axes.spines.right\": False,\n",
        "    \"axes.linewidth\": 1.2,\n",
        "    \"xtick.major.size\": 6, \"ytick.major.size\": 6,\n",
        "    \"xtick.major.width\": 1.2, \"ytick.major.width\": 1.2,\n",
        "})\n",
        "\n",
        "def normalize_lon(lon_1d, *arrays_latlon):\n",
        "    lon = np.asarray(lon_1d).copy()\n",
        "    if lon.min() >= -180 and lon.max() <= 180 and np.all(np.diff(lon) > 0):\n",
        "        return lon, arrays_latlon\n",
        "    lon_wrapped = ((lon + 180) % 360) - 180\n",
        "    order = np.argsort(lon_wrapped)\n",
        "    lon_sorted = lon_wrapped[order]\n",
        "    reindexed = [np.asarray(arr)[:, order] for arr in arrays_latlon]\n",
        "    return lon_sorted, tuple(reindexed)\n",
        "\n",
        "with netCDF4.Dataset(str(NC_FLUX), \"r\") as ds:\n",
        "    F_TE_cycl_all_3d = ds[\"F_TE_final_cycl\"][0, :, :, :]\n",
        "    F_TE_cycl_strong_3d = ds[\"F_TE_final_cycl\"][5, :, :, :]\n",
        "\n",
        "cycl_int_data = load_nc_var(path=NC_CYC_INT, variable_name=\"cycl_int_final\")\n",
        "\n",
        "F_TE_cycl_weak_3d = F_TE_cycl_all_3d - F_TE_cycl_strong_3d\n",
        "contour_weak = np.mean(cycl_int_data[0] - cycl_int_data[5], axis=0)\n",
        "contour_strong = np.mean(cycl_int_data[5], axis=0)\n",
        "\n",
        "data_weak = np.mean(F_TE_cycl_weak_3d, axis=0)\n",
        "data_strong = np.mean(F_TE_cycl_strong_3d, axis=0)\n",
        "\n",
        "wm_to_pw = (2 * np.pi * A_EARTH) * 1e-15\n",
        "weights_2d = A_EARTH * np.cos(np.deg2rad(latitude))[:, None] * 2 * np.pi * 1e-15\n",
        "\n",
        "field_weak_pw = (data_weak / weights_2d / contour_weak) * wm_to_pw\n",
        "field_strong_pw = (data_strong / weights_2d / contour_strong) * wm_to_pw\n",
        "\n",
        "frac_weak = contour_weak\n",
        "frac_strong = contour_strong\n",
        "\n",
        "lon_map, (field_weak_pw, frac_weak, field_strong_pw, frac_strong) = normalize_lon(\n",
        "    longitude, field_weak_pw, frac_weak, field_strong_pw, frac_strong,\n",
        ")\n",
        "\n",
        "step_pw = 1e8 * wm_to_pw\n",
        "edges_neg = np.arange(-6.5e8 * wm_to_pw, -0.5e8 * wm_to_pw + 1e-12, step_pw)\n",
        "edges_pos = np.arange(0.5e8 * wm_to_pw, 6.5e8 * wm_to_pw + 1e-12, step_pw)\n",
        "levels_map = np.concatenate([edges_neg, edges_pos])\n",
        "\n",
        "neg_bins = len(edges_neg) - 1\n",
        "pos_bins = len(edges_pos) - 1\n",
        "gamma = 1.8\n",
        "t_neg = 0.18 + (0.92 - 0.18) * (np.linspace(0, 1, neg_bins) ** gamma)\n",
        "neg_colors = plt.get_cmap(\"Blues_r\")(t_neg)\n",
        "t_pos = np.linspace(0.25, 0.95, pos_bins)\n",
        "pos_colors = plt.get_cmap(\"Reds\")(t_pos)\n",
        "colors = np.vstack([neg_colors, np.array([[1, 1, 1, 1]]), pos_colors])\n",
        "CM = matplotlib.colors.ListedColormap(colors)\n",
        "NORM = matplotlib.colors.BoundaryNorm(levels_map, CM.N, clip=False)\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize=(12.4, 13.8),\n",
        "                        subplot_kw={\"projection\": cartopy.crs.PlateCarree()})\n",
        "fig.subplots_adjust(left=0.07, right=0.88, top=0.95, bottom=0.08, hspace=0.20)\n",
        "\n",
        "for ax_idx, (field, frac, title, pos_nh, pos_sh) in enumerate([\n",
        "    (field_weak_pw, frac_weak, \"(a) Yearly 1\\u20135 CVU cyclones: transient-eddy energy transport\",\n",
        "     float(np.mean(max_TE_position)), float(np.mean(max_TE_SH_position))),\n",
        "    (field_strong_pw, frac_strong, \"(b) Yearly 6+ CVU cyclones: transient-eddy energy transport\",\n",
        "     float(np.mean(max_TE_position)), float(np.mean(max_TE_SH_position))),\n",
        "]):\n",
        "    ax = axs[ax_idx]\n",
        "    ax.set_extent([-180, 180, -90, 90], crs=cartopy.crs.PlateCarree())\n",
        "    ax.add_feature(cartopy.feature.LAND.with_scale(\"110m\"), facecolor=\"#f6f6f6\", edgecolor=\"none\")\n",
        "    ax.add_feature(cartopy.feature.COASTLINE.with_scale(\"110m\"), linewidth=0.8, zorder=10)\n",
        "    mask = frac < 0.05\n",
        "    cs = ax.contourf(lon_map, latitude, np.where(mask, np.nan, field),\n",
        "                     levels=levels_map, cmap=CM, norm=NORM,\n",
        "                     transform=cartopy.crs.PlateCarree(), extend=\"both\", antialiased=True)\n",
        "    ax.contourf(lon_map, latitude, mask.astype(float), levels=[0.5, 1.0],\n",
        "                colors=[\"#454545\"], alpha=0.75,\n",
        "                transform=cartopy.crs.PlateCarree(), zorder=5)\n",
        "    halo = [matplotlib.patheffects.Stroke(linewidth=6, foreground=\"white\"),\n",
        "            matplotlib.patheffects.Normal()]\n",
        "    ax.plot(lon_map, np.full_like(lon_map, pos_nh), ls=\"--\", lw=3.2, color=\"black\",\n",
        "            path_effects=halo, transform=cartopy.crs.PlateCarree(), zorder=15)\n",
        "    ax.plot(lon_map, np.full_like(lon_map, pos_sh), ls=\"--\", lw=3.2, color=\"black\",\n",
        "            path_effects=halo, transform=cartopy.crs.PlateCarree(), zorder=15)\n",
        "    ax.set_title(title, fontsize=18, pad=10)\n",
        "    ax.set_xticks(np.arange(-180, 181, 30), crs=cartopy.crs.PlateCarree())\n",
        "    ax.set_yticks(np.arange(-80, 81, 20), crs=cartopy.crs.PlateCarree())\n",
        "    ax.tick_params(labelsize=17)\n",
        "\n",
        "cax = fig.add_axes([0.905, 0.12, 0.03, 0.76])\n",
        "cbar = fig.colorbar(cs, cax=cax)\n",
        "\n",
        "tick_step = 4\n",
        "tick_min = int(np.ceil(min(levels_map.min(), np.nanmin(field_weak_pw), np.nanmin(field_strong_pw)) / tick_step) * tick_step)\n",
        "tick_max = int(np.floor(max(levels_map.max(), np.nanmax(field_weak_pw), np.nanmax(field_strong_pw)) / tick_step) * tick_step)\n",
        "ticks = sorted(set(list(np.arange(tick_min, tick_max + tick_step, tick_step)) + [0]))\n",
        "cbar.set_ticks(ticks)\n",
        "cbar.set_ticklabels([str(int(t)) for t in ticks])\n",
        "\n",
        "cbar.ax.minorticks_off()\n",
        "cbar.ax.tick_params(which=\"major\", labelsize=18, length=6, width=1.2)\n",
        "cbar.set_label(\"PW\", fontsize=22, labelpad=12)\n",
        "\n",
        "plt.savefig(\"2d_maps_PW.png\", dpi=600, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figure 7 — Cyclone-centred composites (SH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INTENSE_NC = str(BASE / \"cyclone_centered\" / \"Intense_Composites_SH_only_noleap.nc\")\n",
        "REGULAR_NC = str(BASE / \"cyclone_centered\" / \"Composites_SH_only_noleap.nc\")\n",
        "INTENSE_WM_SH = str(BASE / \"cyclone_centered\" / \"Intense_Composites_W_M_TRACK_SH_.nc\")\n",
        "ALL_WM_SH = str(BASE / \"cyclone_centered\" / \"Composites_W_M_TRACK_SH_.nc\")\n",
        "\n",
        "mpl.rcParams.update({\"font.size\": 14, \"axes.spines.top\": False, \"axes.spines.right\": False})\n",
        "\n",
        "\n",
        "def sym_levels(*arrays, n=31, pct=99):\n",
        "    a = np.nanmax([np.nanpercentile(np.abs(x), pct) for x in arrays])\n",
        "    a = float(a) if np.isfinite(a) and a > 0 else 1.0\n",
        "    return np.linspace(-a, a, n), -a, a\n",
        "\n",
        "\n",
        "def pos_levels(*arrays, n=9, pct=99):\n",
        "    a = np.nanmax([np.nanpercentile(x, pct) for x in arrays])\n",
        "    a = float(a) if np.isfinite(a) and a > 0 else 1.0\n",
        "    return np.linspace(0, a, n), 0, a\n",
        "\n",
        "\n",
        "def monthly_scaler(cnt12):\n",
        "    cnt12 = np.asarray(cnt12, float)\n",
        "    tot = np.nansum(cnt12)\n",
        "    return (12.0 * cnt12 / tot) if tot > 0 else np.ones(12, float)\n",
        "\n",
        "\n",
        "def season_weighted(field_m, weights, months_1based):\n",
        "    idx = [m - 1 for m in months_1based]\n",
        "    scaled = [weights[i] * field_m[i] for i in idx]\n",
        "    return (scaled[0] + scaled[1] + scaled[2]) / 3.0\n",
        "\n",
        "\n",
        "def build_weight_cube(*, lat_row_base, maxpos12):\n",
        "    lat_row_base = np.asarray(lat_row_base, float)\n",
        "    maxpos12 = np.asarray(maxpos12, float).reshape(12)\n",
        "    weight = np.empty((12, lat_row_base.shape[0], 120), float)\n",
        "    for i in range(12):\n",
        "        row_deg = lat_row_base + maxpos12[i]\n",
        "        lat2d = np.tile(row_deg[:, None], (1, 120))\n",
        "        weight[i] = A_EARTH * np.cos(np.deg2rad(lat2d)) * 2 * np.pi * 1e-15\n",
        "    return weight\n",
        "\n",
        "\n",
        "def nice_met_levels(zmin, zmax, interval=60.0):\n",
        "    lo = interval * np.floor(zmin / interval)\n",
        "    hi = interval * np.ceil(zmax / interval)\n",
        "    nlev = max(4, int((hi - lo) / interval) + 1)\n",
        "    return np.linspace(lo, hi, nlev)\n",
        "\n",
        "\n",
        "def ensure_lat_alignment(field2d, lat_src, lat_target):\n",
        "    lat_src = np.asarray(lat_src)\n",
        "    lat_target = np.asarray(lat_target)\n",
        "    if lat_src.shape == lat_target.shape and np.allclose(lat_src, lat_target, atol=1e-9, rtol=0):\n",
        "        return field2d\n",
        "    if lat_src.shape == lat_target.shape and np.allclose(lat_src[::-1], lat_target, atol=1e-9, rtol=0):\n",
        "        return field2d[::-1, :]\n",
        "    asc_src = np.all(np.diff(lat_src) > 0)\n",
        "    asc_targ = np.all(np.diff(lat_target) > 0)\n",
        "    if asc_src != asc_targ:\n",
        "        return field2d[::-1, :]\n",
        "    return field2d\n",
        "\n",
        "\n",
        "def masked_longitudinal_mean(field2d, mask2d):\n",
        "    fld = np.where(mask2d, field2d, np.nan)\n",
        "    return np.nanmean(fld, axis=1)\n",
        "\n",
        "\n",
        "def lat_band_from_mask(mask2d, lat):\n",
        "    rows = np.where(mask2d.any(axis=1))[0]\n",
        "    if rows.size == 0:\n",
        "        return None\n",
        "    ylo, yhi = float(lat[rows[0]]), float(lat[rows[-1]])\n",
        "    if ylo > yhi:\n",
        "        ylo, yhi = yhi, ylo\n",
        "    return ylo, yhi\n",
        "\n",
        "\n",
        "def gray_outside_exact(*, ax, VO_ref, lon, lat, alpha=0.88):\n",
        "    vmax = float(np.nanmax(VO_ref)) + 1.0\n",
        "    ax.contourf(lon, lat, VO_ref, levels=[-1.0, vmax], colors=[\"#505050\"], alpha=alpha, zorder=15)\n",
        "    ax.contour(lon, lat, VO_ref, levels=[-1.0], colors=\"#2f2f2f\", linewidths=1.6, zorder=20)\n",
        "\n",
        "\n",
        "with netCDF4.Dataset(INTENSE_WM_SH, \"r\") as f_intense:\n",
        "    lat_wm_sh = f_intense[\"lat\"][:]\n",
        "    composite_VO_intense = f_intense[\"composite_VO\"][:, :, :]\n",
        "    composite_Z_intense = f_intense[\"composite_Z\"][:, :, :]\n",
        "    composite_SLHF_intense = f_intense[\"composite_SLHF\"][:, :, :]\n",
        "    I_number = f_intense[\"number\"][:].astype(float)\n",
        "\n",
        "with netCDF4.Dataset(ALL_WM_SH, \"r\") as f_all:\n",
        "    composite_VO_all = f_all[\"composite_VO\"][:, :, :]\n",
        "    composite_Z_all = f_all[\"composite_Z\"][:, :, :]\n",
        "    composite_SLHF_all = f_all[\"composite_SLHF\"][:, :, :]\n",
        "    all_number = f_all[\"number\"][:].astype(float)\n",
        "\n",
        "ds6 = xarray.open_dataset(INTENSE_NC)\n",
        "ds15 = xarray.open_dataset(REGULAR_NC)\n",
        "\n",
        "TE6 = ds6[\"composite_TE\"].values\n",
        "SHF6 = ds6[\"composite_Shf\"].values\n",
        "cnt6 = ds6[\"count\"].values.astype(float)\n",
        "x6 = ds6[\"x\"].values\n",
        "y6 = ds6[\"y\"].values\n",
        "\n",
        "TE15 = ds15[\"composite_TE\"].values\n",
        "SHF15 = ds15[\"composite_Shf\"].values\n",
        "cnt15 = ds15[\"count\"].values.astype(float)\n",
        "x15 = ds15[\"x\"].values\n",
        "y15 = ds15[\"y\"].values\n",
        "\n",
        "wgt6 = build_weight_cube(lat_row_base=lat_wm_sh, maxpos12=max_TE_SH_position)\n",
        "wgt15 = build_weight_cube(lat_row_base=lat_wm_sh, maxpos12=max_TE_SH_position)\n",
        "\n",
        "TE6_Wm = TE6 / wgt6\n",
        "SHF6_Wm = SHF6 / wgt6\n",
        "TE15_Wm = TE15 / wgt15\n",
        "SHF15_Wm = SHF15 / wgt15\n",
        "\n",
        "w6 = monthly_scaler(cnt6)\n",
        "w15 = monthly_scaler(cnt15)\n",
        "\n",
        "A_shf = season_weighted(SHF6_Wm, w6, [12, 1, 2]) - season_weighted(SHF6_Wm, w6, [6, 7, 8])\n",
        "B_te = season_weighted(TE6_Wm, w6, [12, 1, 2]) - season_weighted(TE6_Wm, w6, [6, 7, 8])\n",
        "E_shf = season_weighted(SHF15_Wm, w15, [12, 1, 2]) - season_weighted(SHF15_Wm, w15, [6, 7, 8])\n",
        "F_te = season_weighted(TE15_Wm, w15, [12, 1, 2]) - season_weighted(TE15_Wm, w15, [6, 7, 8])\n",
        "\n",
        "SCALE = 1e8\n",
        "A_shf_map = A_shf / SCALE\n",
        "B_te_map = B_te / SCALE\n",
        "E_shf_map = E_shf / SCALE\n",
        "F_te_map = F_te / SCALE\n",
        "\n",
        "I_number_3d = I_number[:, None, None]\n",
        "all_number_3d = all_number[:, None, None]\n",
        "composite_VO_weak = composite_VO_all * (all_number_3d + I_number_3d) / all_number_3d - composite_VO_intense * I_number_3d / all_number_3d\n",
        "composite_Z_weak = composite_Z_all * (all_number_3d + I_number_3d) / all_number_3d - composite_Z_intense * I_number_3d / all_number_3d\n",
        "composite_SLHF_weak = composite_SLHF_all * (all_number_3d + I_number_3d) / all_number_3d - composite_SLHF_intense * I_number_3d / all_number_3d\n",
        "\n",
        "VO_mean_6 = 0.5 * (season_weighted(composite_VO_intense, w6, [12, 1, 2])\n",
        "                    + season_weighted(composite_VO_intense, w6, [6, 7, 8]))\n",
        "VO_mean_15 = 0.5 * (season_weighted(composite_VO_weak, w15, [12, 1, 2])\n",
        "                     + season_weighted(composite_VO_weak, w15, [6, 7, 8]))\n",
        "\n",
        "Z_DJF_6 = (composite_Z_intense[11] + composite_Z_intense[0] + composite_Z_intense[1]) / 3\n",
        "Z_JJA_6 = np.mean(composite_Z_intense[5:8], axis=0)\n",
        "Z_avg_6 = 0.5 * (Z_DJF_6 + Z_JJA_6)\n",
        "\n",
        "Z_DJF_15 = (composite_Z_weak[11] + composite_Z_weak[0] + composite_Z_weak[1]) / 3\n",
        "Z_JJA_15 = np.mean(composite_Z_weak[5:8], axis=0)\n",
        "Z_avg_15 = 0.5 * (Z_DJF_15 + Z_JJA_15)\n",
        "\n",
        "D_slhf_sum6 = np.nansum(cnt6)\n",
        "D_slhf = np.nansum(composite_SLHF_intense * cnt6[:, None, None], axis=0) / D_slhf_sum6 if D_slhf_sum6 > 0 else np.nan * composite_SLHF_intense[0]\n",
        "# composite_SLHF is already in W/m² (ERA5 slhf+sshf, recomposited from actual data)\n",
        "\n",
        "G_slhf_sum15 = np.nansum(cnt15)\n",
        "G_slhf = np.nansum(composite_SLHF_weak * cnt15[:, None, None], axis=0) / G_slhf_sum15 if G_slhf_sum15 > 0 else np.nan * composite_SLHF_weak[0]\n",
        "# composite_SLHF is already in W/m² (ERA5 slhf+sshf, recomposited from actual data)\n",
        "\n",
        "VO_mean_6_te = ensure_lat_alignment(VO_mean_6, lat_wm_sh, y6)\n",
        "Z_avg_6_te = ensure_lat_alignment(Z_avg_6, lat_wm_sh, y6)\n",
        "VO_mean_15_te = ensure_lat_alignment(VO_mean_15, lat_wm_sh, y15)\n",
        "Z_avg_15_te = ensure_lat_alignment(Z_avg_15, lat_wm_sh, y15)\n",
        "\n",
        "mask_6 = (VO_mean_6_te < -1.0)\n",
        "mask_15 = (VO_mean_15_te < -1.0)\n",
        "\n",
        "C_shf = masked_longitudinal_mean(A_shf, mask_6)\n",
        "C_te = masked_longitudinal_mean(B_te, mask_6)\n",
        "H_shf = masked_longitudinal_mean(E_shf, mask_15)\n",
        "H_te = masked_longitudinal_mean(F_te, mask_15)\n",
        "\n",
        "band6 = lat_band_from_mask(mask_6, y6)\n",
        "band15 = lat_band_from_mask(mask_15, y15)\n",
        "\n",
        "lev_diff_map, vmin_diff, vmax_diff = sym_levels(A_shf_map, E_shf_map, B_te_map, F_te_map, n=31, pct=99)\n",
        "lev_slhf, v0_s, v1_s = pos_levels(D_slhf, G_slhf, n=9, pct=99)\n",
        "\n",
        "fig, axs = plt.subplots(2, 4, figsize=(24, 10))\n",
        "plt.subplots_adjust(wspace=0.30, hspace=0.32, left=0.18, right=0.90, top=0.93, bottom=0.10)\n",
        "\n",
        "X6, Y6 = np.meshgrid(x6, y6)\n",
        "X15, Y15 = np.meshgrid(x15, y15)\n",
        "\n",
        "zmin = float(np.nanmin([np.nanmin(Z_avg_6), np.nanmin(Z_avg_15)]))\n",
        "zmax = float(np.nanmax([np.nanmax(Z_avg_6), np.nanmax(Z_avg_15)]))\n",
        "levels_Z = nice_met_levels(zmin, zmax, interval=60.0)\n",
        "ctr_lw = 2.0\n",
        "lab_fs = 12\n",
        "\n",
        "\n",
        "def storm_lat_line(ax):\n",
        "    ax.axhline(0, color=\"k\", lw=1.2, ls=\"--\", zorder=40)\n",
        "\n",
        "\n",
        "ax = axs[0, 0]\n",
        "im_a = ax.contourf(X6, Y6, A_shf_map, levels=lev_diff_map, cmap=\"bwr\",\n",
        "                   vmin=vmin_diff, vmax=vmax_diff, extend=\"both\", zorder=1)\n",
        "gray_outside_exact(ax=ax, VO_ref=VO_mean_6_te, lon=x6, lat=y6, alpha=0.88)\n",
        "csZ = ax.contour(x6, y6, Z_avg_6_te, levels=levels_Z, colors=\"white\", linewidths=ctr_lw, zorder=25)\n",
        "ax.clabel(csZ, fmt=\"%1.0f\", fontsize=lab_fs, colors=\"white\", inline=0.01)\n",
        "ax.plot(0, 0, \"bx\", ms=7, mew=2, zorder=35)\n",
        "storm_lat_line(ax)\n",
        "ax.set_title(\"(a) DJF-JJA SHF, 6+ CVU\")\n",
        "ax.set_xlabel(\"Longitude from center\")\n",
        "ax.set_ylabel(\"Latitude from center\")\n",
        "\n",
        "ax = axs[0, 1]\n",
        "ax.contourf(X6, Y6, B_te_map, levels=lev_diff_map, cmap=\"bwr\",\n",
        "            vmin=vmin_diff, vmax=vmax_diff, extend=\"both\", zorder=1)\n",
        "gray_outside_exact(ax=ax, VO_ref=VO_mean_6_te, lon=x6, lat=y6, alpha=0.88)\n",
        "csZ = ax.contour(x6, y6, Z_avg_6_te, levels=levels_Z, colors=\"white\", linewidths=ctr_lw, zorder=25)\n",
        "ax.clabel(csZ, fmt=\"%1.0f\", fontsize=lab_fs, colors=\"white\", inline=0.01)\n",
        "ax.plot(0, 0, \"bx\", ms=7, mew=2, zorder=35)\n",
        "storm_lat_line(ax)\n",
        "ax.set_title(\"(b) DJF-JJA TE, 6+ CVU\")\n",
        "ax.set_xlabel(\"Longitude from center\")\n",
        "\n",
        "ax_c = axs[0, 2]\n",
        "ax_c.set_ylim(y6.min(), y6.max())\n",
        "ax_c.plot(C_shf, y6, color=\"#b22222\", lw=2.8, label=\"SHF\")\n",
        "ax_c.plot(C_te, y6, color=\"#1f4e79\", lw=2.8, ls=\"--\", label=\"TE\")\n",
        "storm_lat_line(ax_c)\n",
        "ax_c.axvline(0, color=\"k\", lw=1.2)\n",
        "if band6 is not None:\n",
        "    ylo, yhi = band6\n",
        "    ax_c.axhspan(y6.min(), ylo, color=\"#d0d0d0\", zorder=0)\n",
        "    ax_c.axhspan(yhi, y6.max(), color=\"#d0d0d0\", zorder=0)\n",
        "ax_c.set_title(\"(c) Longitudinal mean\")\n",
        "ax_c.set_xlabel(r\"W m$^{-1}$\")\n",
        "ax_c.legend(frameon=False, fontsize=12)\n",
        "\n",
        "lon_wm = x6\n",
        "ax = axs[0, 3]\n",
        "im_d = ax.contourf(lon_wm, lat_wm_sh, D_slhf, levels=lev_slhf, cmap=\"afmhot_r\",\n",
        "                   vmin=v0_s, vmax=v1_s, extend=\"max\")\n",
        "Z_avg_6_wm = ensure_lat_alignment(Z_avg_6_te, y6, lat_wm_sh)\n",
        "VO_mean_6_wm = ensure_lat_alignment(VO_mean_6_te, y6, lat_wm_sh)\n",
        "csZ = ax.contour(lon_wm, lat_wm_sh, Z_avg_6_wm, levels=levels_Z, colors=\"white\", linewidths=ctr_lw)\n",
        "ax.clabel(csZ, fmt=\"%1.0f\", fontsize=lab_fs, colors=\"white\", inline=0.01)\n",
        "ax.contour(lon_wm, lat_wm_sh, VO_mean_6_wm, levels=[-1.0], colors=\"k\", linewidths=ctr_lw)\n",
        "ax.plot(0, 0, \"bx\", ms=7, mew=2)\n",
        "storm_lat_line(ax)\n",
        "ax.set_title(\"(d) Annual SHF, 6+ CVU\")\n",
        "ax.set_xlabel(\"Longitude from center\")\n",
        "\n",
        "ax = axs[1, 0]\n",
        "ax.contourf(X15, Y15, E_shf_map, levels=lev_diff_map, cmap=\"bwr\",\n",
        "            vmin=vmin_diff, vmax=vmax_diff, extend=\"both\", zorder=1)\n",
        "gray_outside_exact(ax=ax, VO_ref=VO_mean_15_te, lon=x15, lat=y15, alpha=0.88)\n",
        "csZ = ax.contour(x15, y15, Z_avg_15_te, levels=levels_Z, colors=\"white\", linewidths=ctr_lw, zorder=25)\n",
        "ax.clabel(csZ, fmt=\"%1.0f\", fontsize=lab_fs, colors=\"white\", inline=0.01)\n",
        "ax.plot(0, 0, \"bx\", ms=7, mew=2, zorder=35)\n",
        "storm_lat_line(ax)\n",
        "ax.set_title(\"(e) DJF-JJA SHF, 1\\u20135 CVU\")\n",
        "ax.set_xlabel(\"Longitude from center\")\n",
        "ax.set_ylabel(\"Latitude from center\")\n",
        "\n",
        "ax = axs[1, 1]\n",
        "ax.contourf(X15, Y15, F_te_map, levels=lev_diff_map, cmap=\"bwr\",\n",
        "            vmin=vmin_diff, vmax=vmax_diff, extend=\"both\", zorder=1)\n",
        "gray_outside_exact(ax=ax, VO_ref=VO_mean_15_te, lon=x15, lat=y15, alpha=0.88)\n",
        "csZ = ax.contour(x15, y15, Z_avg_15_te, levels=levels_Z, colors=\"white\", linewidths=ctr_lw, zorder=25)\n",
        "ax.clabel(csZ, fmt=\"%1.0f\", fontsize=lab_fs, colors=\"white\", inline=0.01)\n",
        "ax.plot(0, 0, \"bx\", ms=7, mew=2, zorder=35)\n",
        "storm_lat_line(ax)\n",
        "ax.set_title(\"(f) DJF-JJA TE, 1\\u20135 CVU\")\n",
        "ax.set_xlabel(\"Longitude from center\")\n",
        "\n",
        "ax_g = axs[1, 2]\n",
        "ax_g.set_ylim(y15.min(), y15.max())\n",
        "ax_g.plot(H_shf, y15, color=\"#b22222\", lw=2.8, label=\"SHF\")\n",
        "ax_g.plot(H_te, y15, color=\"#1f4e79\", lw=2.8, ls=\"--\", label=\"TE\")\n",
        "storm_lat_line(ax_g)\n",
        "ax_g.axvline(0, color=\"k\", lw=1.2)\n",
        "if band15 is not None:\n",
        "    ylo, yhi = band15\n",
        "    ax_g.axhspan(y15.min(), ylo, color=\"#d0d0d0\", zorder=0)\n",
        "    ax_g.axhspan(yhi, y15.max(), color=\"#d0d0d0\", zorder=0)\n",
        "ax_g.set_title(\"(g) Longitudinal mean\")\n",
        "ax_g.set_xlabel(r\"W m$^{-1}$\")\n",
        "ax_g.legend(frameon=False, fontsize=12)\n",
        "\n",
        "ax = axs[1, 3]\n",
        "im_h = ax.contourf(lon_wm, lat_wm_sh, G_slhf, levels=lev_slhf, cmap=\"afmhot_r\",\n",
        "                   vmin=v0_s, vmax=v1_s, extend=\"max\")\n",
        "Z_avg_15_wm = ensure_lat_alignment(Z_avg_15_te, y15, lat_wm_sh)\n",
        "VO_mean_15_wm = ensure_lat_alignment(VO_mean_15_te, y15, lat_wm_sh)\n",
        "csZ = ax.contour(lon_wm, lat_wm_sh, Z_avg_15_wm, levels=levels_Z, colors=\"white\", linewidths=ctr_lw)\n",
        "ax.clabel(csZ, fmt=\"%1.0f\", fontsize=lab_fs, colors=\"white\", inline=0.01)\n",
        "ax.contour(lon_wm, lat_wm_sh, VO_mean_15_wm, levels=[-1.0], colors=\"k\", linewidths=ctr_lw)\n",
        "ax.plot(0, 0, \"bx\", ms=7, mew=2)\n",
        "storm_lat_line(ax)\n",
        "ax.set_title(\"(h) Annual SHF, 1\\u20135 CVU\")\n",
        "ax.set_xlabel(\"Longitude from center\")\n",
        "\n",
        "xmax_lm = np.nanmax(np.abs([C_shf, C_te, H_shf, H_te])) * 1.1\n",
        "for ax_lm in (axs[0, 2], axs[1, 2]):\n",
        "    ax_lm.set_xlim(-xmax_lm, xmax_lm)\n",
        "\n",
        "cax_diff = fig.add_axes([0.1, 0.12, 0.022, 0.76])\n",
        "cb_diff = fig.colorbar(im_a, cax=cax_diff)\n",
        "cb_diff.set_label(r\"Diff ($10^8$ W m$^{-1}$)\", rotation=90, labelpad=18, fontsize=18)\n",
        "cb_diff.ax.yaxis.set_ticks_position(\"left\")\n",
        "cb_diff.ax.yaxis.set_label_position(\"left\")\n",
        "cb_diff.ax.tick_params(labelsize=15, length=6.5, width=1.6)\n",
        "\n",
        "cax_s = fig.add_axes([0.93, 0.12, 0.022, 0.76])\n",
        "cb_s = fig.colorbar(im_d, cax=cax_s)\n",
        "cb_s.set_label(r\"SHF (W m$^{-2}$)\", rotation=270, labelpad=18, fontsize=18)\n",
        "cb_s.ax.tick_params(labelsize=15, length=6.5, width=1.6)\n",
        "\n",
        "plt.savefig(\"Composites.png\", dpi=600, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "ds6.close()\n",
        "ds15.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
